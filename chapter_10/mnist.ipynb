{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d1f059-27f8-4d64-bcea-9fa1ba4c5f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:46.306208Z",
     "iopub.status.busy": "2022-06-27T17:12:46.305562Z",
     "iopub.status.idle": "2022-06-27T17:12:48.219213Z",
     "shell.execute_reply": "2022-06-27T17:12:48.218223Z",
     "shell.execute_reply.started": "2022-06-27T17:12:46.306095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:12:46.897497: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09648f86-b4ee-445e-ad0a-c94d079bf934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.223121Z",
     "iopub.status.busy": "2022-06-27T17:12:48.221923Z",
     "iopub.status.idle": "2022-06-27T17:12:48.404905Z",
     "shell.execute_reply": "2022-06-27T17:12:48.404149Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.223069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full.reshape((-1, 784))\n",
    "X_test = X_test.reshape((-1, 784))\n",
    "print(X_train_full.shape)\n",
    "print(y_train_full.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8adfae1-ae0f-4324-b6fc-8b9f8851ebbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.405820Z",
     "iopub.status.busy": "2022-06-27T17:12:48.405642Z",
     "iopub.status.idle": "2022-06-27T17:12:48.435539Z",
     "shell.execute_reply": "2022-06-27T17:12:48.434203Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.405806Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc28795-2a2f-4eb6-993d-b18d5a7016f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.436875Z",
     "iopub.status.busy": "2022-06-27T17:12:48.436410Z",
     "iopub.status.idle": "2022-06-27T17:12:48.920084Z",
     "shell.execute_reply": "2022-06-27T17:12:48.919212Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.436856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_full = np.r_[X_train, X_val]\n",
    "y_train_full = np.r_[y_train, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cebd4a5-e789-4eba-bb43-91e5570d5a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.921180Z",
     "iopub.status.busy": "2022-06-27T17:12:48.920895Z",
     "iopub.status.idle": "2022-06-27T17:12:48.926743Z",
     "shell.execute_reply": "2022-06-27T17:12:48.926126Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.921165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b73aa49-3b43-4c3c-aeea-27cdf6415780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.927533Z",
     "iopub.status.busy": "2022-06-27T17:12:48.927399Z",
     "iopub.status.idle": "2022-06-27T17:12:48.943908Z",
     "shell.execute_reply": "2022-06-27T17:12:48.943001Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.927521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape=784, output_shape=10, n_hidden=3, n_neurons=200, learning_rate=1e-3, compile=True):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(output_shape, activation=\"softmax\"))\n",
    "                  \n",
    "    if compile:\n",
    "        model.compile(\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467f3eb4-01e1-4ab4-a713-5c3e35d9b723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.946299Z",
     "iopub.status.busy": "2022-06-27T17:12:48.946033Z",
     "iopub.status.idle": "2022-06-27T17:12:48.957995Z",
     "shell.execute_reply": "2022-06-27T17:12:48.956996Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.946281Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tensorboard_cb():\n",
    "    base_dir = os.path.join(os.curdir, \".tflogs\")\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    run_dir = os.path.join(base_dir, run_id)\n",
    "    return keras.callbacks.TensorBoard(run_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a74a2e-80c9-4549-b1f7-776a4659503e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:48.959200Z",
     "iopub.status.busy": "2022-06-27T17:12:48.958928Z",
     "iopub.status.idle": "2022-06-27T17:12:49.474251Z",
     "shell.execute_reply": "2022-06-27T17:12:49.473466Z",
     "shell.execute_reply.started": "2022-06-27T17:12:48.959178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:12:49.019121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:12:49.435186: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:12:49.435223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22307 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = build_model(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b5a8fa6-67b8-4b50-a355-eebcb9340b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:49.475143Z",
     "iopub.status.busy": "2022-06-27T17:12:49.474972Z",
     "iopub.status.idle": "2022-06-27T17:12:49.487423Z",
     "shell.execute_reply": "2022-06-27T17:12:49.486636Z",
     "shell.execute_reply.started": "2022-06-27T17:12:49.475130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 239,410\n",
      "Trainable params: 239,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd54db6-159c-4a04-87ad-0d7c5eb01ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:49.489194Z",
     "iopub.status.busy": "2022-06-27T17:12:49.488646Z",
     "iopub.status.idle": "2022-06-27T17:12:49.495311Z",
     "shell.execute_reply": "2022-06-27T17:12:49.494528Z",
     "shell.execute_reply.started": "2022-06-27T17:12:49.489155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x7f3740e6c910>,\n",
       " <keras.layers.core.dense.Dense at 0x7f3740e6cca0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f3740e6d930>,\n",
       " <keras.layers.core.dense.Dense at 0x7f3740e6c730>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eaed495-0c69-49a3-b36b-b485287b6759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:49.497094Z",
     "iopub.status.busy": "2022-06-27T17:12:49.496563Z",
     "iopub.status.idle": "2022-06-27T17:12:49.505328Z",
     "shell.execute_reply": "2022-06-27T17:12:49.504552Z",
     "shell.execute_reply.started": "2022-06-27T17:12:49.497055Z"
    }
   },
   "outputs": [],
   "source": [
    "class LearningRateCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, initial_learning_rate, final_learning_rate, steps):\n",
    "        self.factor = math.exp(math.log(final_learning_rate/float(initial_learning_rate))/steps)\n",
    "        self.losses = []\n",
    "        self.learning_rates = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.losses.append(logs.get(\"loss\"))\n",
    "        learning_rate = keras.backend.get_value(self.model.optimizer.learning_rate)\n",
    "        self.learning_rates.append(learning_rate)\n",
    "        keras.backend.set_value(self.model.optimizer.learning_rate, learning_rate*self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da8f2a25-f01f-4298-95be-84036bb24ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:49.506954Z",
     "iopub.status.busy": "2022-06-27T17:12:49.506481Z",
     "iopub.status.idle": "2022-06-27T17:12:54.112788Z",
     "shell.execute_reply": "2022-06-27T17:12:54.111310Z",
     "shell.execute_reply.started": "2022-06-27T17:12:49.506921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/500 [..............................] - ETA: 6:06 - loss: 2.3154 - accuracy: 0.1091WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0045s). Check your callbacks.\n",
      " 33/500 [>.............................] - ETA: 2s - loss: 2.3137 - accuracy: 0.0945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:12:50.500216: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 7ms/step - loss: nan - accuracy: 0.2903 - val_loss: nan - val_accuracy: 0.1018\n"
     ]
    }
   ],
   "source": [
    "n_steps = 500\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"mnist_digits_model.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "tensorboard_cb = get_tensorboard_cb()\n",
    "learning_rate_callback = LearningRateCallback(1e-5, 1e1, n_steps)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb, learning_rate_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c77af2ae-b8ce-4ea1-af9f-427328456618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:54.115124Z",
     "iopub.status.busy": "2022-06-27T17:12:54.114448Z",
     "iopub.status.idle": "2022-06-27T17:12:54.218343Z",
     "shell.execute_reply": "2022-06-27T17:12:54.217632Z",
     "shell.execute_reply.started": "2022-06-27T17:12:54.114983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approximate best learning rate: 0.08392840226491292\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = np.array(learning_rate_callback.learning_rates)\n",
    "losses = np.array(learning_rate_callback.losses)\n",
    "\n",
    "idx = losses < 10\n",
    "learning_rates_clean = learning_rates[idx]\n",
    "losses_clean = losses[idx]\n",
    "\n",
    "plt.plot(learning_rates_clean, losses_clean)\n",
    "best_idx = np.argmin(losses_clean)\n",
    "best_learning_rate = learning_rates[best_idx] / 15.\n",
    "print(f\"approximate best learning rate: {best_learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18cc9400-e01e-4039-b8cf-c4d8cb360f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:54.219228Z",
     "iopub.status.busy": "2022-06-27T17:12:54.219072Z",
     "iopub.status.idle": "2022-06-27T17:12:54.226215Z",
     "shell.execute_reply": "2022-06-27T17:12:54.225516Z",
     "shell.execute_reply.started": "2022-06-27T17:12:54.219214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe079bc-fef5-42b3-b7a5-9e86c4fdd4f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:12:54.227029Z",
     "iopub.status.busy": "2022-06-27T17:12:54.226873Z",
     "iopub.status.idle": "2022-06-27T17:16:32.620948Z",
     "shell.execute_reply": "2022-06-27T17:16:32.619797Z",
     "shell.execute_reply.started": "2022-06-27T17:12:54.227016Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2898 - accuracy: 0.9113 - val_loss: 0.1227 - val_accuracy: 0.9596\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1086 - accuracy: 0.9669 - val_loss: 0.0986 - val_accuracy: 0.9674\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0735 - accuracy: 0.9768 - val_loss: 0.0903 - val_accuracy: 0.9720\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.0750 - val_accuracy: 0.9768\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.0597 - val_accuracy: 0.9812\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0836 - val_accuracy: 0.9750\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0884 - val_accuracy: 0.9746\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0690 - val_accuracy: 0.9792\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0711 - val_accuracy: 0.9800\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0669 - val_accuracy: 0.9804\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0738 - val_accuracy: 0.9806\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1058 - val_accuracy: 0.9744\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0856 - val_accuracy: 0.9792\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0757 - val_accuracy: 0.9834\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 7.4378e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9826\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.0863e-04 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9836\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.0489e-04 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9828\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.4187e-04 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9832\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.1117e-04 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9824\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.8192e-04 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9832\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.6668e-04 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9824\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.5121e-04 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9822\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3731e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9818\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2837e-04 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9830\n"
     ]
    }
   ],
   "source": [
    "model = build_model(learning_rate=best_learning_rate)\n",
    "\n",
    "model_file = \"mnist_digits_model.h5\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_file, save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "tensorboard_cb = get_tensorboard_cb()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aa577f8-dce3-456a-9f99-7be1ef6f4aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:16:32.623108Z",
     "iopub.status.busy": "2022-06-27T17:16:32.622701Z",
     "iopub.status.idle": "2022-06-27T17:16:34.079066Z",
     "shell.execute_reply": "2022-06-27T17:16:34.077449Z",
     "shell.execute_reply.started": "2022-06-27T17:16:32.623074Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0757 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07571646571159363, 0.9781000018119812]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(model_file)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e20658-2f5c-41d9-8c8d-241d775163cb",
   "metadata": {},
   "source": [
    "### Bayesian Optimization Using skopt BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4157ebde-95ca-4c9b-b8af-e3cb504792e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:16:34.081448Z",
     "iopub.status.busy": "2022-06-27T17:16:34.080926Z",
     "iopub.status.idle": "2022-06-27T17:48:05.617862Z",
     "shell.execute_reply": "2022-06-27T17:48:05.616165Z",
     "shell.execute_reply.started": "2022-06-27T17:16:34.081402Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:16:35.076588: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:16:35.076590: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:16:35.081094: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:16:36.388277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:16:36.392927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:16:36.392927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:16:36.915859: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:16:36.915899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19764 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:16:36.922393: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:16:36.922429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19760 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:16:36.938753: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:16:36.938786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19740 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:16:37.947612: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:16:37.985352: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:16:38.018353: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.1362 - accuracy: 0.2352\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.0996\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 2.4008 - accuracy: 0.1250Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: nan - accuracy: 0.1027\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.1462\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.0988Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "   1/1250 [..............................] - ETA: 5s - loss: nan - accuracy: 0.0938Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.0987Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: nan - accuracy: 0.0987\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:17:32.976966: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:17:32.978976: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:17:32.979523: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:17:34.269762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:17:34.306761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:17:34.329992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:17:34.759266: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:17:34.759306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16915 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:17:34.780998: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:17:34.781056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16891 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:17:34.789620: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:17:34.789656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16885 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:17:35.841996: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:17:35.897932: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:17:35.906658: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3523 - accuracy: 0.8925\n",
      "1227/1250 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.8922Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3384 - accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3497 - accuracy: 0.8934\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1299 - accuracy: 0.9610\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1282 - accuracy: 0.9629\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1313 - accuracy: 0.9609\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.1456 - accuracy: 0.9375Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0886 - accuracy: 0.9730\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9726Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0932 - accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0914 - accuracy: 0.9725\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.0286 - accuracy: 1.0000Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0684 - accuracy: 0.9787\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0694 - accuracy: 0.9791\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0722 - accuracy: 0.9779\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0515 - accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0532 - accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0545 - accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0440 - accuracy: 0.9855\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0435 - accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0433 - accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0330 - accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0370 - accuracy: 0.9884\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0356 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0305 - accuracy: 0.9904\n",
      "1234/1250 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9904Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0262 - accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0320 - accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0246 - accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0261 - accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0230 - accuracy: 0.9932\n",
      "  12/1250 [..............................] - ETA: 5s - loss: 0.0021 - accuracy: 1.0000    Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0234 - accuracy: 0.9929\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0241 - accuracy: 0.9920\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:18:34.980356: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:18:34.980356: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:18:34.980356: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:18:36.292655: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:18:36.298265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:18:36.310903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:18:36.858504: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:18:36.858559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14052 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:18:36.879410: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:18:36.879447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14026 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:18:36.880253: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:18:36.880281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14026 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:18:37.940152: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:18:37.950826: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:18:37.975567: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3007 - accuracy: 0.9081\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3131 - accuracy: 0.9035\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3040 - accuracy: 0.9084\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.2707 - accuracy: 0.9375Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1142 - accuracy: 0.9647\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1185 - accuracy: 0.9637\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1180 - accuracy: 0.9638\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0774 - accuracy: 0.9757\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0792 - accuracy: 0.9747\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.0433 - accuracy: 0.9784Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0786 - accuracy: 0.9752\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 0.0517 - accuracy: 0.9688Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0556 - accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0576 - accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0555 - accuracy: 0.9822\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0376 - accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0402 - accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0402 - accuracy: 0.9869\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0293 - accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0321 - accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0304 - accuracy: 0.9903\n",
      "  25/1250 [..............................] - ETA: 5s - loss: 0.0163 - accuracy: 0.9950Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0224 - accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0213 - accuracy: 0.9929\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0165 - accuracy: 0.9949\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0160 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0094 - accuracy: 0.9968\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0097 - accuracy: 0.9970\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0115 - accuracy: 0.9963\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:19:33.947584: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:19:33.947584: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:19:33.947584: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:19:35.262366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:19:35.264111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:19:35.321924: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:19:35.832429: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:19:35.832472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11187 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:19:35.844079: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:19:35.844117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11175 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:19:35.854532: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:19:35.854569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11169 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:19:36.906478: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:19:36.912878: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:19:36.966432: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.6822 - accuracy: 0.7821\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.6806 - accuracy: 0.7944\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.8559 - accuracy: 0.7053Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.8511 - accuracy: 0.7071\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2795 - accuracy: 0.9238\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2907 - accuracy: 0.9220\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3388 - accuracy: 0.9112\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.1990 - accuracy: 0.9471Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2201 - accuracy: 0.9419\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2439 - accuracy: 0.9367\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2774 - accuracy: 0.9307\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1900 - accuracy: 0.9497\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2123 - accuracy: 0.9434\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2378 - accuracy: 0.9395\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1663 - accuracy: 0.9568\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1977 - accuracy: 0.9485\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2310 - accuracy: 0.9428\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1568 - accuracy: 0.9593\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1803 - accuracy: 0.9523\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3402 - accuracy: 0.9205\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.1569 - accuracy: 0.9591Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1510 - accuracy: 0.9618\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1820 - accuracy: 0.9527\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2377 - accuracy: 0.9411\n",
      "  99/1250 [=>............................] - ETA: 4s - loss: 0.1237 - accuracy: 0.9678Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1357 - accuracy: 0.9653\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1703 - accuracy: 0.9560\n",
      "  86/1250 [=>............................] - ETA: 4s - loss: 0.1832 - accuracy: 0.9549Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2150 - accuracy: 0.9459\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1536 - accuracy: 0.9616\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2130 - accuracy: 0.9492\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2137 - accuracy: 0.9470\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1298 - accuracy: 0.9670\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1791 - accuracy: 0.9543\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1883 - accuracy: 0.9529\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:20:33.001000: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:20:33.001000: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:20:33.014559: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:20:34.303272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:20:34.335563: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:20:34.335568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:20:34.836643: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:20:34.836684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8332 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:20:34.840763: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:20:34.840798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8330 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:20:34.845012: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:20:34.845040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8326 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:20:35.923937: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:20:35.953244: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:20:35.987505: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.5826 - accuracy: 0.8161\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.5773 - accuracy: 0.8248\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7728 - accuracy: 0.7512\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2009 - accuracy: 0.9445\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2289 - accuracy: 0.9367\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2071 - accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1521 - accuracy: 0.9570\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1653 - accuracy: 0.9540\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1565 - accuracy: 0.9575\n",
      "  14/1250 [..............................] - ETA: 5s - loss: 0.1960 - accuracy: 0.9464Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1246 - accuracy: 0.9647\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1304 - accuracy: 0.9644\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1288 - accuracy: 0.9647\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1185 - accuracy: 0.9667\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1018 - accuracy: 0.9712\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1130 - accuracy: 0.9693\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1168 - accuracy: 0.9674\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0955 - accuracy: 0.9725\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0992 - accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0923 - accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0837 - accuracy: 0.9767\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.0591 - accuracy: 0.9808Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0822 - accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0852 - accuracy: 0.9757\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0659 - accuracy: 0.9809\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0728 - accuracy: 0.9796\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0759 - accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0678 - accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0700 - accuracy: 0.9812\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0706 - accuracy: 0.9801\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0672 - accuracy: 0.9811\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0719 - accuracy: 0.9811\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "   1/1250 [..............................] - ETA: 4:02 - loss: 2.3505 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:21:33.253510: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 335/1250 [=======>......................] - ETA: 3s - loss: 0.6147 - accuracy: 0.8044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:21:34.579669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 448/1250 [=========>....................] - ETA: 2s - loss: 0.5302 - accuracy: 0.8325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:21:35.093917: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:21:35.093970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6319 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 521/1250 [===========>..................] - ETA: 2s - loss: 0.4822 - accuracy: 0.8484Epoch 1/10\n",
      "  15/1250 [..............................] - ETA: 4s - loss: 2.0245 - accuracy: 0.3250   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:21:36.269850: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3151 - accuracy: 0.9029\n",
      " 479/1250 [==========>...................] - ETA: 3s - loss: 0.4881 - accuracy: 0.8464Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3140 - accuracy: 0.9016\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3058 - accuracy: 0.9051\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1162 - accuracy: 0.9637\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1236 - accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1168 - accuracy: 0.9640\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0792 - accuracy: 0.9755\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0827 - accuracy: 0.9743\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.0058 - accuracy: 1.0000Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0778 - accuracy: 0.9769\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0581 - accuracy: 0.9815\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0602 - accuracy: 0.9815\n",
      " 482/1250 [==========>...................] - ETA: 3s - loss: 0.0528 - accuracy: 0.9834Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0591 - accuracy: 0.9814\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0430 - accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0468 - accuracy: 0.9851\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0451 - accuracy: 0.9857\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0342 - accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0366 - accuracy: 0.9886\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0264 - accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0322 - accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0262 - accuracy: 0.9918\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0211 - accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0247 - accuracy: 0.9922\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.0118 - accuracy: 0.9976Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0234 - accuracy: 0.9927\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0177 - accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0217 - accuracy: 0.9934\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0165 - accuracy: 0.9948\n",
      "625/625 [==============================] - 2s 3ms/step loss: 0.0177 - accuracy: 0.99\n",
      "625/625 [==============================] - 2s 3ms/step loss: 0.0183 - accuracy: 0.99\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0184 - accuracy: 0.9943\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3241 - accuracy: 0.9002\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3297 - accuracy: 0.8985\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3200 - accuracy: 0.9007\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1249 - accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1249 - accuracy: 0.9618\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1237 - accuracy: 0.9632\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.1981 - accuracy: 0.9062Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0877 - accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0876 - accuracy: 0.9732\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0861 - accuracy: 0.9732\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0668 - accuracy: 0.9783\n",
      "1207/1250 [===========================>..] - ETA: 0s - loss: 0.0652 - accuracy: 0.9795Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0665 - accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0657 - accuracy: 0.9793\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0522 - accuracy: 0.9836\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0508 - accuracy: 0.9838\n",
      "  38/1250 [..............................] - ETA: 5s - loss: 0.0241 - accuracy: 0.9918Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0516 - accuracy: 0.9839\n",
      "  14/1250 [..............................] - ETA: 5s - loss: 0.0188 - accuracy: 0.9933Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0439 - accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0413 - accuracy: 0.9862\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0397 - accuracy: 0.9874\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0365 - accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0364 - accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0357 - accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0278 - accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0290 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0243 - accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0209 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0240 - accuracy: 0.9925\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0249 - accuracy: 0.9923\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0230 - accuracy: 0.9923\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3989 - accuracy: 0.8802\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4007 - accuracy: 0.8805\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3554 - accuracy: 0.8912\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1333 - accuracy: 0.9603\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1447 - accuracy: 0.9576\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1405 - accuracy: 0.9588\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.2240 - accuracy: 0.9688Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0988 - accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1031 - accuracy: 0.9685\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1053 - accuracy: 0.9689\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.0176 - accuracy: 1.0000Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0740 - accuracy: 0.9777\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0801 - accuracy: 0.9760\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0781 - accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0611 - accuracy: 0.9814\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0652 - accuracy: 0.9806\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0656 - accuracy: 0.9798\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0508 - accuracy: 0.9844\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9818Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0559 - accuracy: 0.9818\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0551 - accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0404 - accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0425 - accuracy: 0.9863\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0429 - accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0407 - accuracy: 0.9867\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0376 - accuracy: 0.9884\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0374 - accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0327 - accuracy: 0.9894\n",
      "1193/1250 [===========================>..] - ETA: 0s - loss: 0.0361 - accuracy: 0.9889Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0336 - accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0358 - accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0274 - accuracy: 0.9911\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0302 - accuracy: 0.9907\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0316 - accuracy: 0.9898\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.2005\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0023 - accuracy: 0.2290\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2989 - accuracy: 0.1183\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "1225/1250 [============================>.] - ETA: 0s - loss: 2.3078 - accuracy: 0.1050Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3078 - accuracy: 0.1050\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9410 - accuracy: 0.2384\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3080 - accuracy: 0.1026\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.1581Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.1578\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3081 - accuracy: 0.1042\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3075 - accuracy: 0.1061\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3075 - accuracy: 0.1036\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3078 - accuracy: 0.1041\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "1183/1250 [===========================>..] - ETA: 0s - loss: 2.3079 - accuracy: 0.1052Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3080 - accuracy: 0.1044\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3077 - accuracy: 0.1059\n",
      "1225/1250 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.0988Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3077 - accuracy: 0.1049\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: nan - accuracy: 0.0987\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3044 - accuracy: 0.9072\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3035 - accuracy: 0.9068\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2793 - accuracy: 0.9141\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1363 - accuracy: 0.9582\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1237 - accuracy: 0.9616\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1310 - accuracy: 0.9611\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1017 - accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0919 - accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0976 - accuracy: 0.9705\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0779 - accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0680 - accuracy: 0.9782\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0765 - accuracy: 0.9765\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0657 - accuracy: 0.9803\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0553 - accuracy: 0.9819\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0628 - accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0492 - accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0432 - accuracy: 0.9862\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0496 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0410 - accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0354 - accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0429 - accuracy: 0.9869\n",
      "  28/1250 [..............................] - ETA: 4s - loss: 0.0263 - accuracy: 0.9888Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0409 - accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0288 - accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0342 - accuracy: 0.9891\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0323 - accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0251 - accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0286 - accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0289 - accuracy: 0.9903\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0170 - accuracy: 0.9940\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0245 - accuracy: 0.9919\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.2916 - accuracy: 0.1076\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.2929 - accuracy: 0.1155\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.2941 - accuracy: 0.1266\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.2493 - accuracy: 0.1329\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.2494 - accuracy: 0.2128\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2567 - accuracy: 0.1945\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 2.1924 - accuracy: 0.2572Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.1815 - accuracy: 0.1747\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.1543 - accuracy: 0.2558\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.1788 - accuracy: 0.2134\n",
      "  25/1250 [..............................] - ETA: 5s - loss: 2.1309 - accuracy: 0.2175Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0475 - accuracy: 0.3423\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0807 - accuracy: 0.2428\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0373 - accuracy: 0.2594\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9040 - accuracy: 0.4349\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8956 - accuracy: 0.3528\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8655 - accuracy: 0.3573\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.6014 - accuracy: 0.5090\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5633 - accuracy: 0.4832\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6590 - accuracy: 0.4636\n",
      "  36/1250 [..............................] - ETA: 5s - loss: 1.3396 - accuracy: 0.5938Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1942 - accuracy: 0.6418\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1625 - accuracy: 0.6528\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3726 - accuracy: 0.5549\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9108 - accuracy: 0.7200\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.8846 - accuracy: 0.7312Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8844 - accuracy: 0.7313\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0918 - accuracy: 0.6467\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7472 - accuracy: 0.7726\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7356 - accuracy: 0.7784\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9085 - accuracy: 0.7153\n",
      "  59/1250 [>.............................] - ETA: 5s - loss: 0.6647 - accuracy: 0.7956Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.6446 - accuracy: 0.8083\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6496 - accuracy: 0.8078\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7752 - accuracy: 0.7636\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:27:19.225940: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      " 453/1250 [=========>....................] - ETA: 2s - loss: 0.4617 - accuracy: 0.8579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:27:20.564934: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 596/1250 [=============>................] - ETA: 1s - loss: 0.4084 - accuracy: 0.8753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:27:21.048458: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:27:21.048496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5295 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 648/1250 [==============>...............] - ETA: 1s - loss: 0.3798 - accuracy: 0.8836Epoch 1/10\n",
      " 946/1250 [=====================>........] - ETA: 0s - loss: 0.3327 - accuracy: 0.8984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:27:22.130566: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2999 - accuracy: 0.9083\n",
      "1235/1250 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.9129Epoch 2/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2827 - accuracy: 0.9133\n",
      "  15/1250 [..............................] - ETA: 4s - loss: 0.1712 - accuracy: 0.9438Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2871 - accuracy: 0.9117\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1296 - accuracy: 0.9603\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1209 - accuracy: 0.9638\n",
      " 322/1250 [======>.......................] - ETA: 3s - loss: 0.1223 - accuracy: 0.9606Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1250 - accuracy: 0.9616\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0938 - accuracy: 0.9707\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0862 - accuracy: 0.9733\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0899 - accuracy: 0.9723\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0763 - accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0712 - accuracy: 0.9783\n",
      " 348/1250 [=======>......................] - ETA: 3s - loss: 0.0676 - accuracy: 0.9802Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0673 - accuracy: 0.9790\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0582 - accuracy: 0.9811\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0526 - accuracy: 0.9832\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0570 - accuracy: 0.9820\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0512 - accuracy: 0.9840\n",
      "1224/1250 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9855Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0449 - accuracy: 0.9855\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0435 - accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0419 - accuracy: 0.9861\n",
      " 340/1250 [=======>......................] - ETA: 3s - loss: 0.0317 - accuracy: 0.9892Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0350 - accuracy: 0.9887\n",
      " 367/1250 [=======>......................] - ETA: 3s - loss: 0.0307 - accuracy: 0.9895Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0325 - accuracy: 0.9890\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0363 - accuracy: 0.9886\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0296 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0258 - accuracy: 0.9912\n",
      " 890/1250 [====================>.........] - ETA: 1s - loss: 0.0250 - accuracy: 0.9914Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0278 - accuracy: 0.9906\n",
      " 365/1250 [=======>......................] - ETA: 3s - loss: 0.0145 - accuracy: 0.9948Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0229 - accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0213 - accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0271 - accuracy: 0.9911\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "625/625 [==============================] - 2s 3ms/step loss: 0.0153 - accuracy: 0.99\n",
      "625/625 [==============================] - 2s 3ms/step loss: 0.0152 - accuracy: 0.99\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0165 - accuracy: 0.9945\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3680 - accuracy: 0.8895\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3574 - accuracy: 0.8902\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3705 - accuracy: 0.8892\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2117 - accuracy: 0.9386\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2176 - accuracy: 0.9343\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2261 - accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1838 - accuracy: 0.9442\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1757 - accuracy: 0.9479\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1917 - accuracy: 0.9428\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1638 - accuracy: 0.9509\n",
      "1228/1250 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9535Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1573 - accuracy: 0.9533\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1703 - accuracy: 0.9493\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1502 - accuracy: 0.9541\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1469 - accuracy: 0.9561\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1576 - accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1404 - accuracy: 0.9562\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1369 - accuracy: 0.9590\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1450 - accuracy: 0.9555\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1316 - accuracy: 0.9586\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1286 - accuracy: 0.9607\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1343 - accuracy: 0.9592\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1240 - accuracy: 0.9619\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1236 - accuracy: 0.9633\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1299 - accuracy: 0.9611\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1180 - accuracy: 0.9636\n",
      "1182/1250 [===========================>..] - ETA: 0s - loss: 0.1244 - accuracy: 0.9624Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1185 - accuracy: 0.9644\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1243 - accuracy: 0.9624\n",
      "  69/1250 [>.............................] - ETA: 4s - loss: 0.0772 - accuracy: 0.9751Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1133 - accuracy: 0.9643\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1131 - accuracy: 0.9659\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1191 - accuracy: 0.9641\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2770 - accuracy: 0.9153\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2723 - accuracy: 0.9160\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2815 - accuracy: 0.9122\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 0.2730 - accuracy: 0.9688Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1194 - accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1153 - accuracy: 0.9642\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1209 - accuracy: 0.9623\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0832 - accuracy: 0.9745\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0795 - accuracy: 0.9747\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0866 - accuracy: 0.9733\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0699 - accuracy: 0.9773\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0618 - accuracy: 0.9799\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0661 - accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0551 - accuracy: 0.9821\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0512 - accuracy: 0.9834\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9842Epoch 6/10\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0499 - accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0406 - accuracy: 0.9867\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0430 - accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0438 - accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0281 - accuracy: 0.9905\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0341 - accuracy: 0.9884\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0340 - accuracy: 0.9886\n",
      "  14/1250 [..............................] - ETA: 4s - loss: 0.0326 - accuracy: 0.9911Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0185 - accuracy: 0.9934\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0271 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0204 - accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0128 - accuracy: 0.9957\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0147 - accuracy: 0.9953\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0191 - accuracy: 0.9935\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7789 - accuracy: 0.5396\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8125 - accuracy: 0.5291\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8064 - accuracy: 0.5497\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1057 - accuracy: 0.7794\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1185 - accuracy: 0.7829\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1249 - accuracy: 0.7873\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8085 - accuracy: 0.8307\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8112 - accuracy: 0.8323\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8181 - accuracy: 0.8271\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6635 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6637 - accuracy: 0.8530\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6711 - accuracy: 0.8476\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5795 - accuracy: 0.8648\n",
      "1225/1250 [============================>.] - ETA: 0s - loss: 0.5804 - accuracy: 0.8644Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5799 - accuracy: 0.8645\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5869 - accuracy: 0.8604\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5248 - accuracy: 0.8739\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5258 - accuracy: 0.8722\n",
      "  27/1250 [..............................] - ETA: 4s - loss: 0.5108 - accuracy: 0.8657Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5323 - accuracy: 0.8697\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4860 - accuracy: 0.8789\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4877 - accuracy: 0.8777\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4938 - accuracy: 0.8765\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4572 - accuracy: 0.8834\n",
      "1216/1250 [============================>.] - ETA: 0s - loss: 0.4588 - accuracy: 0.8829Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4595 - accuracy: 0.8827\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4649 - accuracy: 0.8820\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4346 - accuracy: 0.8876\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.8863\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.8858\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4164 - accuracy: 0.8905\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4197 - accuracy: 0.8897\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4242 - accuracy: 0.8889\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4919 - accuracy: 0.8486\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4692 - accuracy: 0.8562\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5207 - accuracy: 0.8429\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1613 - accuracy: 0.9548\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1580 - accuracy: 0.9559\n",
      "  12/1250 [..............................] - ETA: 5s - loss: 0.0450 - accuracy: 0.9792Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1637 - accuracy: 0.9542\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1130 - accuracy: 0.9674\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1103 - accuracy: 0.9691\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1176 - accuracy: 0.9663\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0868 - accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0878 - accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0917 - accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0671 - accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0722 - accuracy: 0.9788\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0767 - accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0584 - accuracy: 0.9827\n",
      "1169/1250 [===========================>..] - ETA: 0s - loss: 0.0612 - accuracy: 0.9820Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0599 - accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0616 - accuracy: 0.9816\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0469 - accuracy: 0.9858\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0459 - accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0510 - accuracy: 0.9855\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0426 - accuracy: 0.9872\n",
      "1144/1250 [==========================>...] - ETA: 0s - loss: 0.0433 - accuracy: 0.9871Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0402 - accuracy: 0.9881\n",
      "1199/1250 [===========================>..] - ETA: 0s - loss: 0.0430 - accuracy: 0.9871Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0429 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0374 - accuracy: 0.9887\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0387 - accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0417 - accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0304 - accuracy: 0.9910\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0427 - accuracy: 0.9878\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0332 - accuracy: 0.9899\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2877 - accuracy: 0.9104\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2928 - accuracy: 0.9077\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2818 - accuracy: 0.9108\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1136 - accuracy: 0.9647\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1107 - accuracy: 0.9662\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1089 - accuracy: 0.9655\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0740 - accuracy: 0.9760\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0757 - accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0690 - accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0525 - accuracy: 0.9831\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0531 - accuracy: 0.9831\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0519 - accuracy: 0.9829\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0371 - accuracy: 0.9873\n",
      "1220/1250 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9879Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0379 - accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0359 - accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0312 - accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0313 - accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0205 - accuracy: 0.9934\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0234 - accuracy: 0.9925\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0210 - accuracy: 0.9932\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0192 - accuracy: 0.9940\n",
      "1194/1250 [===========================>..] - ETA: 0s - loss: 0.0183 - accuracy: 0.9939Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0197 - accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0186 - accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0145 - accuracy: 0.9954\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0136 - accuracy: 0.9955\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0099 - accuracy: 0.9973\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4038 - accuracy: 0.8765\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4148 - accuracy: 0.8711\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3868 - accuracy: 0.8829\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2364 - accuracy: 0.9310\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2533 - accuracy: 0.9255\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2435 - accuracy: 0.9287\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2028 - accuracy: 0.9406\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2154 - accuracy: 0.9362\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2090 - accuracy: 0.9389\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1846 - accuracy: 0.9459\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1968 - accuracy: 0.9413\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1946 - accuracy: 0.9426\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1708 - accuracy: 0.9498\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1854 - accuracy: 0.9448\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1737 - accuracy: 0.9481\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1629 - accuracy: 0.9509\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1761 - accuracy: 0.9468\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1653 - accuracy: 0.9514\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1553 - accuracy: 0.9540\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1682 - accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1550 - accuracy: 0.9543\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1572 - accuracy: 0.9525\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1491 - accuracy: 0.9549\n",
      "Epoch 9/10\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1480 - accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1449 - accuracy: 0.9564\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1510 - accuracy: 0.9540\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1420 - accuracy: 0.9572\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1438 - accuracy: 0.9560\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1404 - accuracy: 0.9576\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1350 - accuracy: 0.9587\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2836 - accuracy: 0.9141\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2787 - accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3048 - accuracy: 0.9065\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1258 - accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1139 - accuracy: 0.9643\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1292 - accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0857 - accuracy: 0.9731\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0792 - accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0925 - accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0670 - accuracy: 0.9790\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0616 - accuracy: 0.9790\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 0.0059 - accuracy: 1.0000Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0707 - accuracy: 0.9779\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0524 - accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0520 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0587 - accuracy: 0.9821\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0369 - accuracy: 0.9877\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0429 - accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0453 - accuracy: 0.9860\n",
      "  43/1250 [>.............................] - ETA: 4s - loss: 0.0441 - accuracy: 0.9840Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0308 - accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0356 - accuracy: 0.9884\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0357 - accuracy: 0.9886\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0261 - accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0329 - accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0197 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0283 - accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0282 - accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0139 - accuracy: 0.9956\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4967 - accuracy: 0.8469\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4311 - accuracy: 0.8691\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4866 - accuracy: 0.8565\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2981 - accuracy: 0.9132\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2720 - accuracy: 0.9203\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3048 - accuracy: 0.9147\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2577 - accuracy: 0.9243\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2419 - accuracy: 0.9307\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2745 - accuracy: 0.9238\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2361 - accuracy: 0.9307\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2177 - accuracy: 0.9367\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2519 - accuracy: 0.9288\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2185 - accuracy: 0.9359\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2036 - accuracy: 0.9411\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2408 - accuracy: 0.9318\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2091 - accuracy: 0.9387\n",
      "1191/1250 [===========================>..] - ETA: 0s - loss: 0.2229 - accuracy: 0.9367Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1925 - accuracy: 0.9439\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2240 - accuracy: 0.9368\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2005 - accuracy: 0.9424\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1829 - accuracy: 0.9472\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2170 - accuracy: 0.9384\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1941 - accuracy: 0.9432\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1722 - accuracy: 0.9503\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2029 - accuracy: 0.9409\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1881 - accuracy: 0.9442\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1661 - accuracy: 0.9513\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1924 - accuracy: 0.9431\n",
      "  69/1250 [>.............................] - ETA: 4s - loss: 0.1823 - accuracy: 0.9452Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1843 - accuracy: 0.9449\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1638 - accuracy: 0.9534\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1847 - accuracy: 0.9460\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/envs/hands-on/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.0055 - accuracy: 0.2916\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3033 - accuracy: 0.1082\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0185 - accuracy: 0.2534\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3064 - accuracy: 0.1050\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3064 - accuracy: 0.1066\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3068 - accuracy: 0.1071\n",
      "  12/1250 [..............................] - ETA: 5s - loss: 2.3052 - accuracy: 0.1120Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3068 - accuracy: 0.1036\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3063 - accuracy: 0.1076\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3062 - accuracy: 0.1061\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3069 - accuracy: 0.1023\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2979 - accuracy: 0.1116\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3069 - accuracy: 0.1043\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3061 - accuracy: 0.1070\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3066 - accuracy: 0.1051\n",
      "  36/1250 [..............................] - ETA: 5s - loss: 2.3070 - accuracy: 0.1163Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3069 - accuracy: 0.1049\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3063 - accuracy: 0.1054\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3066 - accuracy: 0.1037\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3061 - accuracy: 0.1067\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3070 - accuracy: 0.1059\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3067 - accuracy: 0.1038\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3066 - accuracy: 0.1063\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3069 - accuracy: 0.1049\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3065 - accuracy: 0.1053\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3067 - accuracy: 0.1040\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3061 - accuracy: 0.1037\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3066 - accuracy: 0.1036\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3065 - accuracy: 0.1037\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3064 - accuracy: 0.1051\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3067 - accuracy: 0.1044\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 2.3066 - accuracy: 0.1028\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:36:27.531520: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:36:27.591014: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:36:27.591014: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:36:28.832132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:36:28.906801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:36:28.941815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:36:29.317027: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:36:29.317070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18845 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:36:29.365968: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:36:29.366005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18797 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:36:29.378225: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:36:29.378263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18789 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:36:30.446450: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:36:30.448579: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:36:30.480289: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4132 - accuracy: 0.8749\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4434 - accuracy: 0.8652\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4345 - accuracy: 0.8662\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1476 - accuracy: 0.9575\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1485 - accuracy: 0.9578\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1498 - accuracy: 0.9579\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1036 - accuracy: 0.9702\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1043 - accuracy: 0.9697\n",
      "Epoch 4/10\n",
      "1220/1250 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9704Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1013 - accuracy: 0.9706\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0805 - accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0787 - accuracy: 0.9768\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.0174 - accuracy: 1.0000Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0783 - accuracy: 0.9769\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0629 - accuracy: 0.9811\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0581 - accuracy: 0.9824\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.1569 - accuracy: 0.9688Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0597 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0511 - accuracy: 0.9849\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0518 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0485 - accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0409 - accuracy: 0.9877\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9881Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0414 - accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0395 - accuracy: 0.9881\n",
      "  67/1250 [>.............................] - ETA: 5s - loss: 0.0223 - accuracy: 0.9916Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0355 - accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0376 - accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0330 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0345 - accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0315 - accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0294 - accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0249 - accuracy: 0.9926\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0257 - accuracy: 0.9922\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0260 - accuracy: 0.9923\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:37:32.474161: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:37:32.474160: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 398/1250 [========>.....................] - ETA: 2s - loss: 2.1686 - accuracy: 0.3177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:37:33.796002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:37:33.828114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 530/1250 [===========>..................] - ETA: 2s - loss: 2.1044 - accuracy: 0.3848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:37:34.252445: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:37:34.252485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16111 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:37:34.275322: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:37:34.275362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16099 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 576/1250 [============>.................] - ETA: 2s - loss: 2.0817 - accuracy: 0.4054Epoch 1/10\n",
      " 591/1250 [=============>................] - ETA: 2s - loss: 2.0748 - accuracy: 0.4105Epoch 1/10\n",
      "   1/1250 [..............................] - ETA: 17:28 - loss: 2.3499 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:37:35.358488: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:37:35.383421: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7551 - accuracy: 0.5764\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7473 - accuracy: 0.5961\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7578 - accuracy: 0.5838\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8671 - accuracy: 0.8215\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8765 - accuracy: 0.8227\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8674 - accuracy: 0.8181\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5799 - accuracy: 0.8611\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5818 - accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5761 - accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4722 - accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4755 - accuracy: 0.8776\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4722 - accuracy: 0.8743\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4155 - accuracy: 0.8884\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4212 - accuracy: 0.8874\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4187 - accuracy: 0.8851\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3805 - accuracy: 0.8958\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3875 - accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3851 - accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3561 - accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3637 - accuracy: 0.8993\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3612 - accuracy: 0.8982\n",
      "  53/1250 [>.............................] - ETA: 4s - loss: 0.3303 - accuracy: 0.9139Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3375 - accuracy: 0.9050\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3460 - accuracy: 0.9029\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3429 - accuracy: 0.9026\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3227 - accuracy: 0.9089\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3317 - accuracy: 0.9068\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3280 - accuracy: 0.9067\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3106 - accuracy: 0.9123\n",
      "625/625 [==============================] - 2s 3ms/step loss: 0.3198 - accuracy: 0.90\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3197 - accuracy: 0.9104\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3156 - accuracy: 0.9098\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:38:29.069138: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:38:29.069138: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:38:29.069137: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:38:30.365924: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:38:30.366732: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:38:30.421737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:38:30.914870: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:38:30.914910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13782 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:38:30.922322: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:38:30.922358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13774 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:38:30.923392: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:38:30.923422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13774 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:38:31.960102: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:38:32.004364: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:38:32.059145: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4107 - accuracy: 0.8744\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4630 - accuracy: 0.8581\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3985 - accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1593 - accuracy: 0.9520\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9546Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1540 - accuracy: 0.9547\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1559 - accuracy: 0.9555\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1165 - accuracy: 0.9657\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1095 - accuracy: 0.9683\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1065 - accuracy: 0.9692\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.1212 - accuracy: 0.9736Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0863 - accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0852 - accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0882 - accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0717 - accuracy: 0.9780\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0701 - accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0684 - accuracy: 0.9798\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0649 - accuracy: 0.9812\n",
      "1229/1250 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9824Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0602 - accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0596 - accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0528 - accuracy: 0.9835\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0490 - accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0510 - accuracy: 0.9854\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0508 - accuracy: 0.9846\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0472 - accuracy: 0.9861\n",
      "  25/1250 [..............................] - ETA: 5s - loss: 0.0250 - accuracy: 0.9900Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0433 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0456 - accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0395 - accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0407 - accuracy: 0.9878\n",
      "  49/1250 [>.............................] - ETA: 5s - loss: 0.0922 - accuracy: 0.9751Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0406 - accuracy: 0.9877\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0336 - accuracy: 0.9898\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0385 - accuracy: 0.9891\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:39:28.942715: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:39:28.942715: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:39:28.942716: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:39:30.238816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:39:30.238816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:39:30.297397: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:39:30.773862: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:39:30.773903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10925 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:39:30.775987: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:39:30.776026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10923 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:39:30.788833: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:39:30.788865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10909 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:39:31.810735: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:39:31.826804: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:39:31.847717: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2473 - accuracy: 0.9248\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2487 - accuracy: 0.9244\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2499 - accuracy: 0.9237\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1046 - accuracy: 0.9681\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1024 - accuracy: 0.9690\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1058 - accuracy: 0.9679\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0672 - accuracy: 0.9792\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0674 - accuracy: 0.9778\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 0.0683 - accuracy: 0.9688Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0705 - accuracy: 0.9785\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0485 - accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0459 - accuracy: 0.9858\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9849Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0503 - accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0328 - accuracy: 0.9896\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0339 - accuracy: 0.9895\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 0.0213 - accuracy: 1.0000Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0372 - accuracy: 0.9886\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0255 - accuracy: 0.9926\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0188 - accuracy: 0.9946\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0144 - accuracy: 0.9963\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0174 - accuracy: 0.9952\n",
      "Epoch 8/10\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0116 - accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0092 - accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0115 - accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0077 - accuracy: 0.9986\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0059 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0076 - accuracy: 0.9986\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0047 - accuracy: 0.9996\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0035 - accuracy: 0.9998\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9997\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:40:23.335989: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:40:23.335990: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:40:23.344131: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-27 13:40:24.625554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:40:24.627488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:40:24.687629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 13:40:25.162562: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:40:25.162608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8080 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:40:25.180619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:40:25.180658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8062 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-06-27 13:40:25.194476: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:40:25.194509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8054 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:40:26.254847: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:40:26.265103: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-27 13:40:26.274550: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3964 - accuracy: 0.8766\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3945 - accuracy: 0.8801\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3916 - accuracy: 0.8792\n",
      "   1/1250 [..............................] - ETA: 5s - loss: 0.0458 - accuracy: 1.0000Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1473 - accuracy: 0.9571\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1500 - accuracy: 0.9558\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1511 - accuracy: 0.9552\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1059 - accuracy: 0.9684\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1089 - accuracy: 0.9675\n",
      "  36/1250 [..............................] - ETA: 5s - loss: 0.0613 - accuracy: 0.9826Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1058 - accuracy: 0.9693\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0803 - accuracy: 0.9757\n",
      "1209/1250 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9755Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0819 - accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0851 - accuracy: 0.9745\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0642 - accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0645 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0654 - accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0542 - accuracy: 0.9829\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0543 - accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0543 - accuracy: 0.9827\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0535 - accuracy: 0.9840\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0440 - accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0473 - accuracy: 0.9856\n",
      "  84/1250 [=>............................] - ETA: 5s - loss: 0.0325 - accuracy: 0.9903Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0420 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0404 - accuracy: 0.9876\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0414 - accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0374 - accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0308 - accuracy: 0.9909\n",
      "  95/1250 [=>............................] - ETA: 5s - loss: 0.0403 - accuracy: 0.9862Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0356 - accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0298 - accuracy: 0.9902\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0305 - accuracy: 0.9902\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0265 - accuracy: 0.9919\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "  21/1250 [..............................] - ETA: 3s - loss: 1.9386 - accuracy: 0.3884  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:41:27.034224: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 462/1250 [==========>...................] - ETA: 2s - loss: 0.5338 - accuracy: 0.8461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:41:28.374263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 608/1250 [=============>................] - ETA: 1s - loss: 0.4885 - accuracy: 0.8588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:41:28.887614: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-27 13:41:28.887649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6049 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 694/1250 [===============>..............] - ETA: 1s - loss: 0.4679 - accuracy: 0.8646Epoch 1/10\n",
      "  34/1250 [..............................] - ETA: 3s - loss: 1.5651 - accuracy: 0.5423 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:41:29.998675: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3877 - accuracy: 0.8874\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3920 - accuracy: 0.8862\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3950 - accuracy: 0.8863\n",
      " 999/1250 [======================>.......] - ETA: 0s - loss: 0.2464 - accuracy: 0.9274Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2320 - accuracy: 0.9324\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2431 - accuracy: 0.9282\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2367 - accuracy: 0.9315\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1916 - accuracy: 0.9419\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2057 - accuracy: 0.9395\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1998 - accuracy: 0.9430\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1653 - accuracy: 0.9506\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1825 - accuracy: 0.9453\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1759 - accuracy: 0.9490\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1666 - accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1491 - accuracy: 0.9553\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1598 - accuracy: 0.9525\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1533 - accuracy: 0.9559\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1362 - accuracy: 0.9596\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1481 - accuracy: 0.9568\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1448 - accuracy: 0.9561\n",
      " 302/1250 [======>.......................] - ETA: 3s - loss: 0.1394 - accuracy: 0.9596Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1270 - accuracy: 0.9617\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1383 - accuracy: 0.9592\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1376 - accuracy: 0.9585\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1196 - accuracy: 0.9632\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1314 - accuracy: 0.9614\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1304 - accuracy: 0.9609\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1128 - accuracy: 0.9651\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1238 - accuracy: 0.9631\n",
      " 920/1250 [=====================>........] - ETA: 1s - loss: 0.1216 - accuracy: 0.9624Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1242 - accuracy: 0.9621\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1065 - accuracy: 0.9664\n",
      "625/625 [==============================] - 2s 2ms/step loss: 0.1210 - accuracy: 0.96\n",
      "625/625 [==============================] - 2s 2ms/step loss: 0.1213 - accuracy: 0.96\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1202 - accuracy: 0.9648\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4054 - accuracy: 0.8753\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3861 - accuracy: 0.8795\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4086 - accuracy: 0.8725\n",
      "  14/1250 [..............................] - ETA: 4s - loss: 0.1973 - accuracy: 0.9464Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2114 - accuracy: 0.9362\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2188 - accuracy: 0.9352\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2213 - accuracy: 0.9343\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1778 - accuracy: 0.9471\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1853 - accuracy: 0.9460\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1842 - accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1589 - accuracy: 0.9536\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1644 - accuracy: 0.9516\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1710 - accuracy: 0.9478\n",
      "Epoch 5/10\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1533 - accuracy: 0.9540\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1556 - accuracy: 0.9537\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1521 - accuracy: 0.9554\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1420 - accuracy: 0.9582\n",
      "1193/1250 [===========================>..] - ETA: 0s - loss: 0.1422 - accuracy: 0.9577Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1460 - accuracy: 0.9564\n",
      "  40/1250 [..............................] - ETA: 4s - loss: 0.1225 - accuracy: 0.9648Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1425 - accuracy: 0.9577\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1358 - accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1413 - accuracy: 0.9578\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1362 - accuracy: 0.9609\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1265 - accuracy: 0.9627\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1353 - accuracy: 0.9598\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1270 - accuracy: 0.9611\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1227 - accuracy: 0.9638\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1284 - accuracy: 0.9613\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1229 - accuracy: 0.9640\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1180 - accuracy: 0.9648\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1216 - accuracy: 0.9629\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1210 - accuracy: 0.9646\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3271 - accuracy: 0.9002\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3324 - accuracy: 0.8975\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3630 - accuracy: 0.8899\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1312 - accuracy: 0.9609\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1238 - accuracy: 0.9631\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1303 - accuracy: 0.9613\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0869 - accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0872 - accuracy: 0.9722\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0916 - accuracy: 0.9724\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0635 - accuracy: 0.9796\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0646 - accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0710 - accuracy: 0.9782\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0514 - accuracy: 0.9838\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9823Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0497 - accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0566 - accuracy: 0.9823\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0440 - accuracy: 0.9867\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0407 - accuracy: 0.9875\n",
      "Epoch 7/10\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0464 - accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0381 - accuracy: 0.9879\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0361 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0367 - accuracy: 0.9890\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0341 - accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0332 - accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0260 - accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0310 - accuracy: 0.9907\n",
      "  13/1250 [..............................] - ETA: 5s - loss: 0.0274 - accuracy: 0.9880Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0229 - accuracy: 0.9929\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0240 - accuracy: 0.9924\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2455 - accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2459 - accuracy: 0.9240\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2439 - accuracy: 0.9241\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1029 - accuracy: 0.9687\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1008 - accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1033 - accuracy: 0.9687\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0680 - accuracy: 0.9791\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0639 - accuracy: 0.9796\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0673 - accuracy: 0.9788\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0474 - accuracy: 0.9852\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0454 - accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0466 - accuracy: 0.9850\n",
      "  27/1250 [..............................] - ETA: 4s - loss: 0.0215 - accuracy: 0.9942Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0363 - accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0285 - accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0342 - accuracy: 0.9892\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0231 - accuracy: 0.9935\n",
      "1199/1250 [===========================>..] - ETA: 0s - loss: 0.0219 - accuracy: 0.9935Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0201 - accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0220 - accuracy: 0.9934\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0154 - accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0116 - accuracy: 0.9972\n",
      "1206/1250 [===========================>..] - ETA: 0s - loss: 0.0152 - accuracy: 0.9956Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0103 - accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0100 - accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9994Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0043 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0063 - accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0041 - accuracy: 0.9995\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0023 - accuracy: 0.9999\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5115 - accuracy: 0.8538\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4502 - accuracy: 0.8723\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4154 - accuracy: 0.8797\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2283 - accuracy: 0.9359\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1957 - accuracy: 0.9449\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1857 - accuracy: 0.9470\n",
      "  15/1250 [..............................] - ETA: 4s - loss: 0.2252 - accuracy: 0.9417Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1553 - accuracy: 0.9556\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1987 - accuracy: 0.9463\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1519 - accuracy: 0.9560\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1653 - accuracy: 0.9538\n",
      "1223/1250 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9627Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1317 - accuracy: 0.9623\n",
      "   1/1250 [..............................] - ETA: 4s - loss: 0.0072 - accuracy: 1.0000Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1329 - accuracy: 0.9629\n",
      "  27/1250 [..............................] - ETA: 4s - loss: 0.0895 - accuracy: 0.9699Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1493 - accuracy: 0.9596\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1270 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1136 - accuracy: 0.9681\n",
      "  28/1250 [..............................] - ETA: 4s - loss: 0.1092 - accuracy: 0.9721Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1293 - accuracy: 0.9645\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1168 - accuracy: 0.9684\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0991 - accuracy: 0.9718\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1273 - accuracy: 0.9661\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0970 - accuracy: 0.9726\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0843 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1103 - accuracy: 0.9693\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0940 - accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0822 - accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1082 - accuracy: 0.9718\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0788 - accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0740 - accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1058 - accuracy: 0.9720\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0835 - accuracy: 0.9768\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0742 - accuracy: 0.9801\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2978 - accuracy: 0.9081\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3028 - accuracy: 0.9052\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2900 - accuracy: 0.9101\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1145 - accuracy: 0.9648\n",
      "1228/1250 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9639Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1179 - accuracy: 0.9640\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1145 - accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0811 - accuracy: 0.9748\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0808 - accuracy: 0.9751\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0791 - accuracy: 0.9752\n",
      "  39/1250 [..............................] - ETA: 4s - loss: 0.0650 - accuracy: 0.9824Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0618 - accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0593 - accuracy: 0.9816\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0654 - accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0429 - accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0503 - accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0430 - accuracy: 0.9862\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0417 - accuracy: 0.9866\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0364 - accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0379 - accuracy: 0.9876\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0291 - accuracy: 0.9908\n",
      "1186/1250 [===========================>..] - ETA: 0s - loss: 0.0303 - accuracy: 0.9905Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0339 - accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0314 - accuracy: 0.9902\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0297 - accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0249 - accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0279 - accuracy: 0.9915\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0284 - accuracy: 0.9908\n",
      "1167/1250 [===========================>..] - ETA: 0s - loss: 0.0270 - accuracy: 0.9913Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0212 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0197 - accuracy: 0.9940\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0185 - accuracy: 0.9944\n",
      "625/625 [==============================] - 2s 2ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2079 - accuracy: 0.9365\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0878 - accuracy: 0.9730\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0600 - accuracy: 0.9809\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0418 - accuracy: 0.9863\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0309 - accuracy: 0.9899\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0218 - accuracy: 0.9937\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0166 - accuracy: 0.9949\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0115 - accuracy: 0.9968\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0069 - accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0047 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=3,\n",
       "              estimator=KerasClassifier(callbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f373d653640&gt;], compile=False, epochs=10, learning_rate=0.001, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;], model=&lt;function build_model at 0x7f3740e179a0&gt;, n_hidden=3, n_neurons=200, optimizer=&lt;class &#x27;keras.optimizers.optimizer_v2.gradient_descent.SGD&#x27;&gt;),\n",
       "              n_iter=32, n_jobs=16,\n",
       "              search_spaces={&#x27;n_hidden&#x27;: (1, 5), &#x27;n_neurons&#x27;: (20, 300),\n",
       "                             &#x27;optimizer__learning_rate&#x27;: (0.001, 1.0,\n",
       "                                                          &#x27;uniform&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=3,\n",
       "              estimator=KerasClassifier(callbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f373d653640&gt;], compile=False, epochs=10, learning_rate=0.001, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;], model=&lt;function build_model at 0x7f3740e179a0&gt;, n_hidden=3, n_neurons=200, optimizer=&lt;class &#x27;keras.optimizers.optimizer_v2.gradient_descent.SGD&#x27;&gt;),\n",
       "              n_iter=32, n_jobs=16,\n",
       "              search_spaces={&#x27;n_hidden&#x27;: (1, 5), &#x27;n_neurons&#x27;: (20, 300),\n",
       "                             &#x27;optimizer__learning_rate&#x27;: (0.001, 1.0,\n",
       "                                                          &#x27;uniform&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7f3740e179a0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;class &#x27;keras.optimizers.optimizer_v2.gradient_descent.SGD&#x27;&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=[&#x27;accuracy&#x27;]\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f373d653640&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=10\n",
       "\tn_hidden=3\n",
       "\tn_neurons=200\n",
       "\tlearning_rate=0.001\n",
       "\tcompile=False\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7f3740e179a0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;class &#x27;keras.optimizers.optimizer_v2.gradient_descent.SGD&#x27;&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=[&#x27;accuracy&#x27;]\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f373d653640&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=10\n",
       "\tn_hidden=3\n",
       "\tn_neurons=200\n",
       "\tlearning_rate=0.001\n",
       "\tcompile=False\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=KerasClassifier(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f373d653640>], compile=False, epochs=10, learning_rate=0.001, loss='sparse_categorical_crossentropy', metrics=['accuracy'], model=<function build_model at 0x7f3740e179a0>, n_hidden=3, n_neurons=200, optimizer=<class 'keras.optimizers.optimizer_v2.gradient_descent.SGD'>),\n",
       "              n_iter=32, n_jobs=16,\n",
       "              search_spaces={'n_hidden': (1, 5), 'n_neurons': (20, 300),\n",
       "                             'optimizer__learning_rate': (0.001, 1.0,\n",
       "                                                          'uniform')})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "clf = KerasClassifier(\n",
    "    model=build_model,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=keras.optimizers.SGD,\n",
    "    callbacks=[early_stopping_cb],\n",
    "    epochs=10,\n",
    "    n_hidden=3,\n",
    "    n_neurons=200,\n",
    "    learning_rate=1e-3,\n",
    "    compile=False,\n",
    ")\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    clf,\n",
    "    {\n",
    "        \"n_hidden\": (1, 5),\n",
    "        \"n_neurons\": (20, 300),\n",
    "        \"optimizer__learning_rate\": (1e-3, 1., \"uniform\")\n",
    "    },\n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=16,\n",
    ")\n",
    "\n",
    "opt.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c8f9992-6005-4585-a0ab-95faee9c2bf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:48:05.620373Z",
     "iopub.status.busy": "2022-06-27T17:48:05.619849Z",
     "iopub.status.idle": "2022-06-27T17:48:05.629013Z",
     "shell.execute_reply": "2022-06-27T17:48:05.627793Z",
     "shell.execute_reply.started": "2022-06-27T17:48:05.620324Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('n_hidden', 1), ('n_neurons', 300), ('optimizer__learning_rate', 0.3749868952421413)])\n",
      "0.9788666666666667\n",
      "{'model': <function build_model at 0x7f3740e179a0>, 'build_fn': None, 'warm_start': False, 'random_state': None, 'optimizer': <class 'keras.optimizers.optimizer_v2.gradient_descent.SGD'>, 'loss': 'sparse_categorical_crossentropy', 'metrics': ['accuracy'], 'batch_size': None, 'validation_batch_size': None, 'verbose': 1, 'callbacks': [<keras.callbacks.EarlyStopping object at 0x7f373d840760>], 'validation_split': 0.0, 'shuffle': True, 'run_eagerly': False, 'epochs': 50, 'n_hidden': 1, 'n_neurons': 300, 'learning_rate': 0.001, 'compile': False, 'optimizer__learning_rate': 0.3749868952421413, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "print(opt.best_params_)\n",
    "print(opt.best_score_)\n",
    "best_params = opt.best_estimator_.get_params()\n",
    "best_params.update({'epochs': 50})\n",
    "print(best_params)\n",
    "best_clf = KerasClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59939231-809d-4c95-961a-bd0d35e71f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:48:05.631611Z",
     "iopub.status.busy": "2022-06-27T17:48:05.630619Z",
     "iopub.status.idle": "2022-06-27T17:54:18.924888Z",
     "shell.execute_reply": "2022-06-27T17:54:18.923341Z",
     "shell.execute_reply.started": "2022-06-27T17:48:05.631567Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2059 - accuracy: 0.9367\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0865 - accuracy: 0.9738\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0588 - accuracy: 0.9811\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0406 - accuracy: 0.9870\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0314 - accuracy: 0.9899\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0217 - accuracy: 0.9934\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 8.0595e-04 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 6.7882e-04 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.0011e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 5.5586e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 5.0683e-04 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 4.6649e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 4.3952e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 4.0971e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 3.8500e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 3.6682e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 3.4732e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 3.2979e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 3.1644e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 3.0228e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.9038e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.7889e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.6877e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.5765e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.4952e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.4058e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3208e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.2541e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.1770e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.1215e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.0477e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.9991e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.9430e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.8871e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.8332e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.7921e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.7460e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.7043e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.6636e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.6218e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.5857e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.5520e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.5191e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7f3740e179a0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;class &#x27;keras.optimizers.optimizer_v2.gradient_descent.SGD&#x27;&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=[&#x27;accuracy&#x27;]\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f373d840760&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tn_hidden=1\n",
       "\tn_neurons=300\n",
       "\tlearning_rate=0.001\n",
       "\tcompile=False\n",
       "\toptimizer__learning_rate=0.3749868952421413\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7f3740e179a0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;class &#x27;keras.optimizers.optimizer_v2.gradient_descent.SGD&#x27;&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=[&#x27;accuracy&#x27;]\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f373d840760&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tn_hidden=1\n",
       "\tn_neurons=300\n",
       "\tlearning_rate=0.001\n",
       "\tcompile=False\n",
       "\toptimizer__learning_rate=0.3749868952421413\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function build_model at 0x7f3740e179a0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=<class 'keras.optimizers.optimizer_v2.gradient_descent.SGD'>\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=['accuracy']\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[<keras.callbacks.EarlyStopping object at 0x7f373d840760>]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tn_hidden=1\n",
       "\tn_neurons=300\n",
       "\tlearning_rate=0.001\n",
       "\tcompile=False\n",
       "\toptimizer__learning_rate=0.3749868952421413\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc30924-aa65-4140-b708-479dabb9b5ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T17:54:18.927284Z",
     "iopub.status.busy": "2022-06-27T17:54:18.926749Z",
     "iopub.status.idle": "2022-06-27T17:54:20.032161Z",
     "shell.execute_reply": "2022-06-27T17:54:20.030904Z",
     "shell.execute_reply.started": "2022-06-27T17:54:18.927237Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e8fa9-e5ed-46dc-ae95-48cc4488f27c",
   "metadata": {},
   "source": [
    "It seems that the best score is found by a single layer with the maximum number of neurons specified in the search space. This suggests that it might be a good idea to expand the search space into more neurons per layer. For the purposes of this exercise I'll stop here, as my main goal was to learn how to use a keras model with bayesian optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
