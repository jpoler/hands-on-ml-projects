{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chapter_12_layer_normalization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLd8l3E+REYewbtWwS9mbm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["12. Implement a custom layer that performs Layer Normalization (we will use this type of layer in Chapter 15 ):\n","\n","The build() method should define two trainable weights α and β , both of shape input_shape[-1:] and data type tf.float32 . α should be initialized with 1s, and β with 0s.\n","\n","The call() method should compute the mean μ and standard deviation σ of each instance’s features. For this, you can use tf.nn.moments(inputs, axes=-1, keepdims=True) , which returns the mean μ and the variance σ 2 of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return α ⊗( X μ )/( σ + ε ) + β , where ⊗ represents itemwise multiplication ( * ) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001).\n","\n","Ensure that your custom layer produces the same (or very nearly the same) output as the keras.layers.LayerNormalization layer.\n"],"metadata":{"id":"hH7MsilgTX-4"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow.keras as keras"],"metadata":{"id":"eTp5a-H6UhDX","executionInfo":{"status":"ok","timestamp":1656958906623,"user_tz":240,"elapsed":129,"user":{"displayName":"Jon Poler","userId":"13423372355356044593"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class LayerNormalization(keras.layers.Layer):\n","  def build(self, input_shape, eps=None):\n","    self.alpha = self.add_weight(shape=input_shape[-1:], initializer=tf.ones_initializer(), trainable=True)\n","    self.beta = self.add_weight(shape=input_shape[-1:], initializer=tf.zeros_initializer(), trainable=True)\n","    self.eps = eps or keras.backend.epsilon()\n","\n","  def call(self, inputs):\n","    mean, variance = tf.nn.moments(inputs, axes=-1, keepdims=True)\n","    stddev = tf.sqrt(variance)\n","    normalized = (inputs - mean) / (stddev + self.eps)\n","    return tf.multiply(self.alpha, normalized) + self.beta\n"],"metadata":{"id":"5oQhR8BrTjYu","executionInfo":{"status":"ok","timestamp":1656959189924,"user_tz":240,"elapsed":161,"user":{"displayName":"Jon Poler","userId":"13423372355356044593"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["X = tf.random.normal((100, 10), mean=10, stddev=5.0)\n","\n","\n","custom_normalization = LayerNormalization()\n","custom_normalization.build(X.shape)\n","X_custom_normalized = custom_normalization.call(X)\n","\n","keras_normalization = keras.layers.LayerNormalization()\n","keras_normalization.build(X.shape)\n","X_keras_normalized = keras_normalization.call(X)\n","\n","tf.debugging.assert_near(X_custom_normalized, X_keras_normalized, atol=0.001, rtol=0.)"],"metadata":{"id":"pggLCRaOZbLc","executionInfo":{"status":"ok","timestamp":1656959269211,"user_tz":240,"elapsed":147,"user":{"displayName":"Jon Poler","userId":"13423372355356044593"}}},"execution_count":20,"outputs":[]}]}