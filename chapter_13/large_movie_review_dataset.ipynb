{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd2c28f-a0e7-40e3-9c80-58f6421b9dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:05.006433Z",
     "iopub.status.busy": "2022-07-15T01:32:05.005855Z",
     "iopub.status.idle": "2022-07-15T01:32:06.362204Z",
     "shell.execute_reply": "2022-07-15T01:32:06.361517Z",
     "shell.execute_reply.started": "2022-07-15T01:32:05.006314Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:32:05.193082: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a71ff9-25cf-4758-9cd6-d39ceb5f6908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:06.364217Z",
     "iopub.status.busy": "2022-07-15T01:32:06.363645Z",
     "iopub.status.idle": "2022-07-15T01:32:06.369625Z",
     "shell.execute_reply": "2022-07-15T01:32:06.369004Z",
     "shell.execute_reply.started": "2022-07-15T01:32:06.364192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos', 'neg']\n",
      "['pos', 'neg']\n"
     ]
    }
   ],
   "source": [
    "def base_data_dir():\n",
    "    return os.path.join(os.curdir, \"large_movie_review_dataset\", \"aclImdb\")\n",
    "\n",
    "def train_data_dir():\n",
    "    return os.path.join(base_data_dir(), \"train\")\n",
    "\n",
    "def test_data_dir():\n",
    "    return os.path.join(base_data_dir(), \"test\")\n",
    "\n",
    "print(os.listdir(train_data_dir()))\n",
    "print(os.listdir(test_data_dir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e4f8b9-89a0-4c55-a429-18be4c56fe5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:06.370739Z",
     "iopub.status.busy": "2022-07-15T01:32:06.370480Z",
     "iopub.status.idle": "2022-07-15T01:32:06.384698Z",
     "shell.execute_reply": "2022-07-15T01:32:06.384345Z",
     "shell.execute_reply.started": "2022-07-15T01:32:06.370718Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def configure_dataset(dataset):\n",
    "    return dataset.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6fae32-f735-4271-b23d-788df7b97d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:06.385315Z",
     "iopub.status.busy": "2022-07-15T01:32:06.385183Z",
     "iopub.status.idle": "2022-07-15T01:32:09.536809Z",
     "shell.execute_reply": "2022-07-15T01:32:09.536073Z",
     "shell.execute_reply.started": "2022-07-15T01:32:06.385304Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:32:07.243607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-14 21:32:07.648996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22307 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 10000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 15000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.utils.text_dataset_from_directory(train_data_dir(), seed=42)\n",
    "validation_dataset = keras.utils.text_dataset_from_directory(test_data_dir(), seed=42, validation_split=.4, subset=\"validation\")\n",
    "test_dataset = keras.utils.text_dataset_from_directory(test_data_dir(), seed=42, validation_split=.4, subset=\"training\")\n",
    "\n",
    "train_dataset = configure_dataset(train_dataset)\n",
    "validation_dataset = configure_dataset(validation_dataset)\n",
    "test_dataset = configure_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "350ba0cd-2d16-4350-ae56-25322ddbfa57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:09.538375Z",
     "iopub.status.busy": "2022-07-15T01:32:09.538103Z",
     "iopub.status.idle": "2022-07-15T01:32:09.684247Z",
     "shell.execute_reply": "2022-07-15T01:32:09.683246Z",
     "shell.execute_reply.started": "2022-07-15T01:32:09.538362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      " b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"], shape=(2,), dtype=string)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[b'This movie is a mix of a dark comedy and a drama, about two guys who worked in a Butcher\\'s shop and wanted to build up their own. When they finally fulfilled that dream, they faced a new problem: there were no clients! One day, by accident, one guy dies in the refrigerator room, and a new kind of butcher\\'s business begins\\xc2\\x85 They start selling human flesh, saying to the clients it\\'s just chicken\\xc2\\x85 and their business starts to improve: Human flesh sells good! Oh! I forgot to say something\\xc2\\x85 These guys aren\\'t normal! There\\'s really something missing in their brains! <br /><br />The movie has some nice dark humour scenes, but it is, in my opinion, mostly a drama. One that shows us what is inside the head of a psychopath, what are his motivations to what he does. I must confess I was a bit surprised with the ending of the movie, because I never expected they could make it without been discovered, but that\\'s probably because I see too many Hollywood movies\\xc2\\x85 What I mean by this is that in Hollywood\\'s cinema we always expect the punishment of the guys which do the \"bad things\". There\\'s always a morality protecting the \"good values\", in spite of we all know that in \"real life\" it doesn\\'t happen this way too many times\\xc2\\x85 And I liked this movie mostly because of that, because it fits in a kind of cinema which is true, frontal, without fake moralities, and which \"see\" what is on the other side, behind the \"conventional morality\"\\xc2\\x85 It just happens in independent cinema (especially in the European)! <br /><br />Besides, there\\'re excellent performances by Nikolaj Lie Kass and Mads Mikkelsen (especially the first one) in the roles of the \"disturbed guys\"\\xc2\\x85 <br /><br />Very nice Danish film!'\n",
      " b\"Lackawanna Blues is a drama through and through. It details the life of a strong woman by the name of Rachel Crosby (S. Epatha Merkerson). Rachel is referred to as Nanny by all who know her, but she could have just as easily been called Wonder Woman. She epitomized strength, will power, confidence and resolve. She owned a home that she used to house just about every type of person that society would reject. Her tenants consisted of a lesbian, a psychotic war veteran, an amputee, and a host of other vagrants that made the home miles away from ordinary. Each successive event Rachel took in stride and handled flawlessly. She wasn't a dictator devoid of compassion, but in fact she was quite the opposite. She displayed compassion almost to a fault by giving shelter and refuge to so many that she seemed to over-extend herself.<br /><br />Merkerson did a good job, but I believe this role was right up her alley anyway. The movie had an even keel never straying from Rachel. There were of course dramatic moments but they were to be expected. Nothing was ever to shocking or profound other than Rachel herself.\"], shape=(2,), dtype=string)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[b'DeCoteau has to be one of the worst \"directors\" working today in any genre, and it has nothing to do with his movies usually containing homoerotism and having guys run around in their matching boxer briefs. Remember... anyone in tight black underwear is satanic and evil and want to suck out your blood/soul... such deep symbolism here). I just sat through The Sisterhood to give him his fair shakes, I try to watch every horror movie I can and this one had Barbara (FROM BEYOND, RE-ANIMATOR) Crampton in it (I had previously been sucked in to the world of DeCoteau thanks to Linnea Quigley, Adrienne Barbeau and several other actresses I like).<br /><br />Lemme tell you what about The Sisterhood... Like the other reviewer pointed out, the supposed plot involves lesbian vampires on a college campus. But never has a parade of hot young babes (\"actresses\" if you want) running around dressed in bras, panties and bikinis been so boring. The movie has no plot, no gore, no nudity and the dialog is ridiculous and seems like they made it up as they go along. Parts are put in slow-motion and repeated many times to push the running time up. About ten minutes of this one consists of characters just walking around on campus (oh, the excitement!) that looks more like a hotel resort than any college I\\'ve ever been to. And the acting is the absolute worst. The only thing these girls do well is lean forward and bend over to show off their bodies. The cast were so devoid of talent that I\\'d be shocked to see any of them get a one-day walk-on role on Passions in the future. Ditto for the guys. Yeah DeCoteau squeezed more hot guys in underwear in this one, too... Guys who should be in some K-Mart brochure instead of trying to act. Do these people actually have to audition or just show up in Dave\\'s office and take their clothes off? I think the answer is obvious.<br /><br />I am willing to give any movie a chance if 1.) it\\'s intelligently written, well directed, original and competently acted (or hell, even ambitious and stylish)... Or 2.) it is chock full of gore, nudity, assorted trashiness and/or it\\'s unintentionally hilarious. David DeCoteau\\'s movies deliver NONE of that and they do it on better-than-usual production values for direct-to-video flicks. What a waste! So what is the appeal, especially with the advent of porn of the soft- and hard-core variety that\\'s easily accessible to anyone with a computer? I simply cannot answer that.<br /><br />DeCoteau is a gay horror director and could use his resources to put a unique spin on the genre. Instead, he produces mind-numbing drivel without an ounce of talent or intelligence shining through. Ironically, when you think about it, his films are anything BUT pro-gay. They actually make homosexuality seem seedy, secretive and sinister. The obviously gay characters in his films are always trying to corrupt, seduce and/or kill off the innocent, sexually-confused leads. There\\'s no shading here to make things interesting. The protagonists are naive and seldom prove themselves to be strong, assertive or confident in who they are. I would understand this plotting if Jerry Falwell, Fred Phelps or Dr. Laura starting making direct-to-video horror films, but from a gay director, it just goes to show that he puts almost no thought into these beefcake cheese-fests.'\n",
      " b'One of the greatest lessons I ever had in how to watch a movie happened this way: <br /><br />I was working in Roger Corman\\'s offices, like so many other wanabees before and since, I was interning and trying to figure out how it all worked and how to make myself indispensable (hah!). One afternoon Julie Corman, Roger Corman\\'s wife and a producer in her own right, asked me to load up a tape. I\\'m not sure why she wanted to watch it. I got the impression it was a student film or a show reel, something like that, some sort of calling card. Whatever the reasons she had to see it, the only free video machine in the offices at the time happened to be in the room I was working in, and I was the nearest person to the machine. I started the tape.<br /><br />Fade in: On screen a figure sat at a desk facing the camera. Behind him, screen left, was a door that opened into the room. Against the far wall was a coat rack. A second character entered through the door and started talking. The first character, the guy at the desk, turned round to reply, (this is all one take, static camera, there are no cuts pans or dolly shots. Just one locked off camera). The second character turned to hang his coat on the coat rack and delivered his next line. Julie Corman said \"I\\'ve seen enough.\" and left the room.<br /><br />What she had seen in the ten seconds of footage she had watched was that the director was an idiot. Opening with two characters who immediately turned their backs to the camera delivering lines? Nope, sorry. Next! That\\'s how long you\\'ve got. Ten seconds. Cock it up in the opening shot and you are dead.<br /><br />I was reminded of that moment while I watched the opening of this piece of crap. After an interminably long travelogue of jungle we see several monkeys apparently throwing themselves into cages. A man carrying a gun laughs. A jet liner lands and we see it taxi the whole way to the terminal. God this is boring! Cut to the interior of the Airport. Two men meet. Aha! Something is happening! They shake hands. Cut to a different angle of the two men -<br /><br />- and the director crosses the line.<br /><br />The first two shots of the movie that have any kind of spatial relationship with each other and the guy has cocked up. \\'Not Crossing The line\\' is one of those basic rules of movie grammar that keeps the characters from jumping about from side to side on the screen and confusing the audience. Audiences don\\'t like to be confused. Mystified? Baffled? Puzzled and intrigued? Yes. Audiences love all of those. Confused? No. You loose them. They walk out. \\'Not Crossing The line\\' is one of those things they pound into you at film school, or should. It\\'s basic stuff. It\\'s not an inviolable rule (there are no inviolable rules) directors break it all the time - but not on the first real cut of the movie.<br /><br />I thought, \"I\\'ve seen enough\". And switched off.'], shape=(2,), dtype=string)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:32:09.606221: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-07-14 21:32:09.641046: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-07-14 21:32:09.677461: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for (text, label) in train_dataset.unbatch().batch(2).take(1):\n",
    "    print(text)\n",
    "    print(label)\n",
    "\n",
    "for (text, label) in validation_dataset.unbatch().batch(2).take(1):\n",
    "    print(text)\n",
    "    print(label)\n",
    "\n",
    "for (text, label) in test_dataset.unbatch().batch(2).take(1):\n",
    "    print(text)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7885a37-3ffd-4f88-8cdd-16cbf799cf29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:09.686182Z",
     "iopub.status.busy": "2022-07-15T01:32:09.685762Z",
     "iopub.status.idle": "2022-07-15T01:32:09.693871Z",
     "shell.execute_reply": "2022-07-15T01:32:09.692812Z",
     "shell.execute_reply.started": "2022-07-15T01:32:09.686146Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def base_log_dir():\n",
    "  return os.path.join(os.curdir, \".tflogs\")\n",
    "\n",
    "def get_tensorboard_cb(profile_batch=0):\n",
    "    base_dir = base_log_dir()\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    run_dir = os.path.join(base_dir, run_id)\n",
    "    file_writer = tf.summary.create_file_writer(run_dir)\n",
    "    file_writer.set_as_default()\n",
    "    return keras.callbacks.TensorBoard(run_dir, profile_batch=profile_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494202b0-1217-4ef0-942b-1c1001659b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:09.696049Z",
     "iopub.status.busy": "2022-07-15T01:32:09.695285Z",
     "iopub.status.idle": "2022-07-15T01:32:09.717789Z",
     "shell.execute_reply": "2022-07-15T01:32:09.716494Z",
     "shell.execute_reply.started": "2022-07-15T01:32:09.696012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "def create_model(dataset, vocab_size=10000, sequence_length=100, embedding_dim=16):\n",
    "    text_vectorization = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "        name=\"text_vectorization\",\n",
    "    )\n",
    "    \n",
    "    text_vectorization.adapt(dataset.map(lambda x, y: x))\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        text_vectorization,\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "        keras.layers.GlobalAveragePooling1D(),\n",
    "        keras.layers.Dense(embedding_dim, activation=\"relu\"),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "            \n",
    "    return model\n",
    "            \n",
    "def train_model(model, train_dataset, validation_dataset):\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=15,\n",
    "        callbacks=[get_tensorboard_cb()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be1d1d0-b236-4888-a1e3-e3a7920b018b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:32:09.719254Z",
     "iopub.status.busy": "2022-07-15T01:32:09.718853Z",
     "iopub.status.idle": "2022-07-15T01:34:24.662585Z",
     "shell.execute_reply": "2022-07-15T01:34:24.661211Z",
     "shell.execute_reply.started": "2022-07-15T01:32:09.719230Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 23/782 [..............................] - ETA: 5s - loss: 0.6930 - accuracy: 0.5177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:32:15.979917: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 11ms/step - loss: 0.5253 - accuracy: 0.6825 - val_loss: 0.3968 - val_accuracy: 0.8101\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3234 - accuracy: 0.8555 - val_loss: 0.3793 - val_accuracy: 0.8184\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2673 - accuracy: 0.8866 - val_loss: 0.3977 - val_accuracy: 0.8159\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2327 - accuracy: 0.9032 - val_loss: 0.4290 - val_accuracy: 0.8104\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2069 - accuracy: 0.9156 - val_loss: 0.4689 - val_accuracy: 0.8064\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1862 - accuracy: 0.9254 - val_loss: 0.5159 - val_accuracy: 0.7992\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1689 - accuracy: 0.9338 - val_loss: 0.5679 - val_accuracy: 0.7938\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1537 - accuracy: 0.9414 - val_loss: 0.6236 - val_accuracy: 0.7907\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1400 - accuracy: 0.9484 - val_loss: 0.6829 - val_accuracy: 0.7855\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1276 - accuracy: 0.9545 - val_loss: 0.7453 - val_accuracy: 0.7825\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1159 - accuracy: 0.9606 - val_loss: 0.8118 - val_accuracy: 0.7791\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1049 - accuracy: 0.9658 - val_loss: 0.8843 - val_accuracy: 0.7771\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0944 - accuracy: 0.9718 - val_loss: 0.9628 - val_accuracy: 0.7745\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0845 - accuracy: 0.9768 - val_loss: 1.0441 - val_accuracy: 0.7707\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0749 - accuracy: 0.9811 - val_loss: 1.1325 - val_accuracy: 0.7691\n"
     ]
    }
   ],
   "source": [
    "model = create_model(train_dataset)\n",
    "train_model(model, train_dataset, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686d4492-0650-47ce-9b7e-7606253d9d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:51:56.128748Z",
     "iopub.status.busy": "2022-07-15T01:51:56.128131Z",
     "iopub.status.idle": "2022-07-15T01:51:56.187040Z",
     "shell.execute_reply": "2022-07-15T01:51:56.186177Z",
     "shell.execute_reply.started": "2022-07-15T01:51:56.128699Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "def embeddings_dir():\n",
    "    return os.path.join(base_log_dir(), \"embeddings\")\n",
    "\n",
    "os.makedirs(embeddings_dir(), exist_ok=True)\n",
    "weights = model.get_layer(\"embedding\").get_weights()[0][1:]\n",
    "vocab = model.get_layer(\"text_vectorization\").get_vocabulary()[1:]\n",
    "weights_var = tf.Variable(weights)\n",
    "print(len(weights))\n",
    "print(len(vocab))\n",
    "\n",
    "vec_path = os.path.join(embeddings_dir(), \"embedding.ckpt\")\n",
    "vocab_path = os.path.join(embeddings_dir(), \"metadata.tsv\")\n",
    "\n",
    "with io.open(vocab_path, \"w\", encoding=\"utf-8\") as vocab_f:\n",
    "    for i, word in enumerate(vocab):\n",
    "        vocab_f.write(word + \"\\n\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights_var)\n",
    "checkpoint.save(vec_path)\n",
    "\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = \"metadata.tsv\"\n",
    "projector.visualize_embeddings(embeddings_dir(), config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
