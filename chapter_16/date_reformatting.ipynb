{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ff63c0-232d-4ed8-b5a0-6bfdb9023810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:14.409919Z",
     "iopub.status.busy": "2022-08-10T02:11:14.408904Z",
     "iopub.status.idle": "2022-08-10T02:11:16.195968Z",
     "shell.execute_reply": "2022-08-10T02:11:16.195155Z",
     "shell.execute_reply.started": "2022-08-10T02:11:14.409794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 22:11:15.016157: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5a5acf-03e8-47f5-9c78-9e89afb599d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:16.197510Z",
     "iopub.status.busy": "2022-08-10T02:11:16.197123Z",
     "iopub.status.idle": "2022-08-10T02:11:16.199826Z",
     "shell.execute_reply": "2022-08-10T02:11:16.199453Z",
     "shell.execute_reply.started": "2022-08-10T02:11:16.197492Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927f1684-3367-4c41-af67-ecea70e58927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:16.200503Z",
     "iopub.status.busy": "2022-08-10T02:11:16.200329Z",
     "iopub.status.idle": "2022-08-10T02:11:16.227210Z",
     "shell.execute_reply": "2022-08-10T02:11:16.226605Z",
     "shell.execute_reply.started": "2022-08-10T02:11:16.200489Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('December 07, 7343',), ('^7343-12-07$',))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_DATE_FORMAT = \"%B %d, %Y\"\n",
    "TARGET_DATE_FORMAT = \"%Y-%m-%d\"\n",
    "\n",
    "def add_start_stop(s):\n",
    "    return \"^\" + s + \"$\"\n",
    "\n",
    "def gen_date_pair():\n",
    "    o = random.randrange(date.min.toordinal(), date.max.toordinal())\n",
    "    d = date.fromordinal(o)\n",
    "    x = d.strftime(SOURCE_DATE_FORMAT)\n",
    "    y = d.strftime(TARGET_DATE_FORMAT)\n",
    "    return (x,), (add_start_stop(y),)\n",
    "\n",
    "gen_date_pair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6959869d-030d-4657-8f1f-5b6cd93a9622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:16.228331Z",
     "iopub.status.busy": "2022-08-10T02:11:16.227977Z",
     "iopub.status.idle": "2022-08-10T02:11:17.066406Z",
     "shell.execute_reply": "2022-08-10T02:11:17.065601Z",
     "shell.execute_reply.started": "2022-08-10T02:11:16.228310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b'November 09, 3950']\n",
      " [b'September 30, 8054']\n",
      " [b'August 09, 4818']\n",
      " [b'October 01, 9269']\n",
      " [b'March 22, 3324']\n",
      " [b'February 03, 6631']\n",
      " [b'October 15, 2672']\n",
      " [b'May 27, 1603']\n",
      " [b'February 05, 2618']\n",
      " [b'December 12, 4347']\n",
      " [b'November 11, 1160']\n",
      " [b'August 05, 4190']\n",
      " [b'September 11, 7594']\n",
      " [b'November 09, 1868']\n",
      " [b'May 14, 9951']\n",
      " [b'September 03, 8768']\n",
      " [b'September 30, 799']\n",
      " [b'October 16, 5207']\n",
      " [b'April 20, 917']\n",
      " [b'June 20, 1834']\n",
      " [b'July 18, 8506']\n",
      " [b'March 23, 4366']\n",
      " [b'October 04, 2511']\n",
      " [b'December 16, 7771']\n",
      " [b'February 21, 9823']\n",
      " [b'September 29, 1174']\n",
      " [b'August 18, 75']\n",
      " [b'April 22, 5804']\n",
      " [b'September 19, 9254']\n",
      " [b'August 28, 1111']\n",
      " [b'July 31, 2473']\n",
      " [b'December 16, 8380']], shape=(32, 1), dtype=string)\n",
      "tf.Tensor(\n",
      "[[b'^3950-11-09$']\n",
      " [b'^8054-09-30$']\n",
      " [b'^4818-08-09$']\n",
      " [b'^9269-10-01$']\n",
      " [b'^3324-03-22$']\n",
      " [b'^6631-02-03$']\n",
      " [b'^2672-10-15$']\n",
      " [b'^1603-05-27$']\n",
      " [b'^2618-02-05$']\n",
      " [b'^4347-12-12$']\n",
      " [b'^1160-11-11$']\n",
      " [b'^4190-08-05$']\n",
      " [b'^7594-09-11$']\n",
      " [b'^1868-11-09$']\n",
      " [b'^9951-05-14$']\n",
      " [b'^8768-09-03$']\n",
      " [b'^799-09-30$']\n",
      " [b'^5207-10-16$']\n",
      " [b'^917-04-20$']\n",
      " [b'^1834-06-20$']\n",
      " [b'^8506-07-18$']\n",
      " [b'^4366-03-23$']\n",
      " [b'^2511-10-04$']\n",
      " [b'^7771-12-16$']\n",
      " [b'^9823-02-21$']\n",
      " [b'^1174-09-29$']\n",
      " [b'^75-08-18$']\n",
      " [b'^5804-04-22$']\n",
      " [b'^9254-09-19$']\n",
      " [b'^1111-08-28$']\n",
      " [b'^2473-07-31$']\n",
      " [b'^8380-12-16$']], shape=(32, 1), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 22:11:16.297071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-09 22:11:16.762633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22307 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def date_dataset(n_samples, batch_size=32):\n",
    "    dates = [gen_date_pair() for _ in range(n_samples)]\n",
    "    return tf.data.Dataset.from_tensor_slices(dates) \\\n",
    "        .shuffle(n_samples) \\\n",
    "        .batch(batch_size, drop_remainder=True) \\\n",
    "        .map(lambda pair: (pair[:, 0], pair[:, 1])) \\\n",
    "        .prefetch(1)\n",
    "\n",
    "for x, y in date_dataset(100).take(1):\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ae8253-bf9e-4aba-bf31-7603463eff07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:17.067392Z",
     "iopub.status.busy": "2022-08-10T02:11:17.067209Z",
     "iopub.status.idle": "2022-08-10T02:11:18.401591Z",
     "shell.execute_reply": "2022-08-10T02:11:18.400416Z",
     "shell.execute_reply.started": "2022-08-10T02:11:17.067376Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "class BatchPreprocessor:\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, X, Y):\n",
    "        X = source_preprocessor(X)\n",
    "        Y_full = target_preprocessor(Y)\n",
    "        Y = Y_full[:, 1:]\n",
    "        \n",
    "        if not self.training:\n",
    "            return X, Y\n",
    "       \n",
    "        X_decoder = Y_full[:, :-1]\n",
    "        X_decoder_length = tf.cast(tf.math.count_nonzero(X_decoder, axis=1), tf.int32)\n",
    "        \n",
    "        return (X, X_decoder, X_decoder_length), Y\n",
    "        \n",
    "def preprocess(ds, source_preprocessor, target_preprocessor, training=False):\n",
    "    return ds.map(BatchPreprocessor(training))\n",
    "\n",
    "train_set = date_dataset(5000)\n",
    "val_set = date_dataset(1000)\n",
    "test_set = date_dataset(1000)\n",
    "\n",
    "source_preprocessor = keras.layers.TextVectorization(standardize=None, split=\"character\", output_mode=\"int\")\n",
    "target_preprocessor = keras.layers.TextVectorization(standardize=None, split=\"character\", output_mode=\"int\")\n",
    "\n",
    "source_preprocessor.adapt(train_set.map(lambda X, Y: X))\n",
    "target_preprocessor.adapt(train_set.map(lambda X, Y: Y))\n",
    "\n",
    "preprocessed_train_set = preprocess(train_set, source_preprocessor, target_preprocessor, training=True)\n",
    "preprocessed_val_set = preprocess(val_set, source_preprocessor, target_preprocessor)\n",
    "preprocessed_test_set = preprocess(test_set, source_preprocessor, target_preprocessor)\n",
    "\n",
    "\n",
    "max_target_length = 0\n",
    "for _, y in preprocessed_val_set:\n",
    "    max_target_length = max(max_target_length, y.shape[1])\n",
    "    \n",
    "print(max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c10dd3e-65b8-4721-a9f5-c823a1499b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.403675Z",
     "iopub.status.busy": "2022-08-10T02:11:18.403205Z",
     "iopub.status.idle": "2022-08-10T02:11:18.412331Z",
     "shell.execute_reply": "2022-08-10T02:11:18.411295Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.403633Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_vocab = set(c for c in source_preprocessor.get_vocabulary())\n",
    "target_vocab = set(c for c in target_preprocessor.get_vocabulary())\n",
    "source_vocab_size = len(source_vocab)\n",
    "target_vocab_size = len(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5493a23d-90c5-407c-85e7-5c3172dd7166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.416032Z",
     "iopub.status.busy": "2022-08-10T02:11:18.415644Z",
     "iopub.status.idle": "2022-08-10T02:11:18.442373Z",
     "shell.execute_reply": "2022-08-10T02:11:18.441290Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.415996Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n"
     ]
    }
   ],
   "source": [
    "target_vocab_start = target_preprocessor(\"^\").numpy()[0]\n",
    "target_vocab_end = target_preprocessor(\"$\").numpy()[0]\n",
    "\n",
    "print(target_vocab_start, target_vocab_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f678b2-be8f-419b-8421-44e6dbb64a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.444022Z",
     "iopub.status.busy": "2022-08-10T02:11:18.443630Z",
     "iopub.status.idle": "2022-08-10T02:11:18.450511Z",
     "shell.execute_reply": "2022-08-10T02:11:18.449527Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.443987Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def base_log_dir():\n",
    "    return os.path.join(os.curdir, \".tflogs\", \"date_reformatting\")\n",
    "\n",
    "def get_tensorboard_cb(callback=keras.callbacks.TensorBoard):\n",
    "    base_dir = base_log_dir()\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    run_dir = os.path.join(base_dir, run_id)\n",
    "    return callback(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65fd721f-38f2-4f7c-bff9-52a74795b574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.452286Z",
     "iopub.status.busy": "2022-08-10T02:11:18.451910Z",
     "iopub.status.idle": "2022-08-10T02:11:18.471055Z",
     "shell.execute_reply": "2022-08-10T02:11:18.470012Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.452252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(keras.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        source_vocab_size, \n",
    "        target_vocab_size, \n",
    "        target_vocab_start, \n",
    "        target_vocab_end, \n",
    "        max_target_length, \n",
    "        embedding_size=5, \n",
    "        n_neurons=32, \n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.target_vocab_start = target_vocab_start\n",
    "        self.target_vocab_end = target_vocab_end\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "        self.source_embeddings = keras.layers.Embedding(source_vocab_size, embedding_size)\n",
    "        self.target_embeddings = keras.layers.Embedding(target_vocab_size, embedding_size)\n",
    "        self.encoder = keras.layers.LSTM(n_neurons, return_state=True)\n",
    "        \n",
    "        decoder_cell = keras.layers.LSTMCell(n_neurons)\n",
    "        output_layer = keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "        training_sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self._training_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, training_sampler, output_layer=output_layer)\n",
    "       \n",
    "        inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(self.target_embeddings)\n",
    "        self._inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "            decoder_cell, \n",
    "            inference_sampler,\n",
    "            output_layer=output_layer,\n",
    "            maximum_iterations=self.max_target_length,\n",
    "            impute_finished=True,\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None:\n",
    "            training = keras.backend.learning_phase()\n",
    "            \n",
    "        \n",
    "        if training:\n",
    "            encoder_inputs, decoder_inputs, decoder_input_lengths = inputs\n",
    "            \n",
    "            encoder_embeddings = self.source_embeddings(encoder_inputs)\n",
    "            decoder_embeddings = self.target_embeddings(decoder_inputs)\n",
    "            encoder_outputs, state_h, state_c = self.encoder(encoder_embeddings)\n",
    "            encoder_state = [state_h, state_c]\n",
    "            \n",
    "            final_outputs, final_state, final_sequence_lengths = self._training_decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=encoder_state,\n",
    "                sequence_length=decoder_input_lengths,\n",
    "            )\n",
    "        else:\n",
    "            encoder_embeddings = self.source_embeddings(inputs)\n",
    "            encoder_outputs, state_h, state_c = self.encoder(encoder_embeddings)\n",
    "            encoder_state = [state_h, state_c]\n",
    "            \n",
    "            decoder_embedding_matrix = self.target_embeddings.variables[0]\n",
    "            start_tokens = tf.cast(tf.fill([inputs.shape[0]], self.target_vocab_start), tf.int32)\n",
    "            end_token = self.target_vocab_end\n",
    "            final_outputs, final_state, final_sequence_lengths = self._inference_decoder(\n",
    "                decoder_embedding_matrix,\n",
    "                initial_state=encoder_state,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=end_token,\n",
    "            )\n",
    "        \n",
    "        pad_len = tf.math.maximum(0, self.max_target_length - tf.reduce_max(final_sequence_lengths))\n",
    "        padded_output = tf.pad(final_outputs.rnn_output, [[0, 0], [0, pad_len], [0, 0]])\n",
    "        Y_proba = tf.nn.softmax(padded_output)\n",
    "        return Y_proba\n",
    "    \n",
    "\n",
    "def build_model(\n",
    "    source_vocab_size, \n",
    "    target_vocab_size, \n",
    "    target_vocab_start, \n",
    "    target_vocab_end, \n",
    "    max_target_length, \n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    embedding_size=5, \n",
    "    n_neurons=32, \n",
    "    n_layers=2, \n",
    "    learning_rate=1e-3, \n",
    "    clipnorm=1.0,\n",
    "):\n",
    "    model = EncoderDecoder(\n",
    "        source_vocab_size, \n",
    "        target_vocab_size, \n",
    "        target_vocab_start,\n",
    "        target_vocab_end,\n",
    "        max_target_length, \n",
    "        embedding_size=embedding_size, \n",
    "        n_neurons=n_neurons,\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=optimizer(learning_rate=learning_rate, clipnorm=clipnorm),\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e022a9-5adc-4de1-a145-74b4a563645f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.472166Z",
     "iopub.status.busy": "2022-08-10T02:11:18.471921Z",
     "iopub.status.idle": "2022-08-10T02:11:18.486362Z",
     "shell.execute_reply": "2022-08-10T02:11:18.485114Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.472143Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LearningRateCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, initial_learning_rate, final_learning_rate, steps):\n",
    "        self.factor = math.exp(math.log(final_learning_rate/float(initial_learning_rate))/steps)\n",
    "        self.losses = []\n",
    "        self.learning_rates = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.losses.append(logs.get(\"loss\"))\n",
    "        learning_rate = keras.backend.get_value(self.model.optimizer.learning_rate)\n",
    "        self.learning_rates.append(learning_rate)\n",
    "        keras.backend.set_value(self.model.optimizer.learning_rate, learning_rate*self.factor)\n",
    "\n",
    "def find_best_learning_rate(\n",
    "    train_set,\n",
    "    val_set,\n",
    "    compiled_model, \n",
    "    n_steps=500,\n",
    "    learning_rate_min=1e-5, \n",
    "    learning_rate_max=1e-1,\n",
    "    ):\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)  \n",
    "    \n",
    "    learning_rate_callback = LearningRateCallback(learning_rate_min, learning_rate_max, n_steps)\n",
    "    \n",
    "    history = compiled_model.fit(\n",
    "      train_set,\n",
    "      epochs=1,\n",
    "      steps_per_epoch=n_steps,\n",
    "      validation_data=val_set,\n",
    "      callbacks=[learning_rate_callback],\n",
    "    )\n",
    "    \n",
    "    \n",
    "    learning_rates = np.array(learning_rate_callback.learning_rates)\n",
    "    losses = np.array(learning_rate_callback.losses)\n",
    "    idx = losses < 10000\n",
    "    learning_rates_clean = learning_rates[idx]\n",
    "    losses_clean = losses[idx]\n",
    "    \n",
    "    plt.plot(learning_rates_clean, losses_clean)\n",
    "    best_idx = np.argmin(losses_clean)\n",
    "    best_learning_rate = learning_rates[best_idx] / 10.\n",
    "    return best_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f35f6e-3ac8-4010-be94-f4c874223063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.488306Z",
     "iopub.status.busy": "2022-08-10T02:11:18.487777Z",
     "iopub.status.idle": "2022-08-10T02:11:18.502038Z",
     "shell.execute_reply": "2022-08-10T02:11:18.500764Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.488267Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_set, \n",
    "    val_set, \n",
    "    compiled_model, \n",
    "    callbacks=None,\n",
    "    n_epochs=20,\n",
    "    steps_per_epoch=None,\n",
    "    tensorboard_callback=keras.callbacks.TensorBoard,\n",
    "    ):\n",
    "    callbacks = callbacks or []\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    builtin_callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        get_tensorboard_cb(callback=tensorboard_callback),\n",
    "    ]\n",
    "    \n",
    "    history = compiled_model.fit(\n",
    "        train_set,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_set,\n",
    "        callbacks=callbacks + builtin_callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f489174e-a445-4c7c-ae90-e8dba55015d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:18.503904Z",
     "iopub.status.busy": "2022-08-10T02:11:18.503468Z",
     "iopub.status.idle": "2022-08-10T02:11:28.598273Z",
     "shell.execute_reply": "2022-08-10T02:11:28.597320Z",
     "shell.execute_reply.started": "2022-08-10T02:11:18.503864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 22:11:23.310492: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-08-09 22:11:23.786036: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 30ms/step - loss: 2.4084 - sparse_categorical_accuracy: 0.1983 - val_loss: 3.3647 - val_sparse_categorical_accuracy: 0.0674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08317638635635376"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(source_vocab_size, target_vocab_size, target_vocab_start, target_vocab_end, max_target_length, n_neurons=16, learning_rate=1e-6)\n",
    "best_learning_rate = find_best_learning_rate(preprocessed_train_set, preprocessed_val_set, model, learning_rate_min=1e-5, learning_rate_max=1e1, n_steps=150)\n",
    "best_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0004ae33-30ad-46c6-9ddd-a56b2481fbed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:11:28.600520Z",
     "iopub.status.busy": "2022-08-10T02:11:28.599923Z",
     "iopub.status.idle": "2022-08-10T02:13:24.905763Z",
     "shell.execute_reply": "2022-08-10T02:13:24.904135Z",
     "shell.execute_reply.started": "2022-08-10T02:11:28.600476Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156/156 [==============================] - 5s 22ms/step - loss: 1.6610 - sparse_categorical_accuracy: 0.3927 - val_loss: 1.7464 - val_sparse_categorical_accuracy: 0.4128\n",
      "Epoch 2/100\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 1.1864 - sparse_categorical_accuracy: 0.5360 - val_loss: 1.6786 - val_sparse_categorical_accuracy: 0.5191\n",
      "Epoch 3/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.8320\n",
      "Epoch 4/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.2001 - sparse_categorical_accuracy: 0.9391 - val_loss: 0.2378 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "156/156 [==============================] - 3s 19ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.3751 - val_sparse_categorical_accuracy: 0.9441\n",
      "Epoch 6/100\n",
      "156/156 [==============================] - 3s 19ms/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 7/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0733 - val_sparse_categorical_accuracy: 0.9931\n",
      "Epoch 8/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 9/100\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0345 - val_sparse_categorical_accuracy: 0.9993\n",
      "Epoch 10/100\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.2023 - val_sparse_categorical_accuracy: 0.9743\n",
      "Epoch 11/100\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9998\n",
      "Epoch 12/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.0270 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "156/156 [==============================] - 3s 19ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0269 - val_sparse_categorical_accuracy: 0.9999\n",
      "Epoch 14/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 9.0538e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 7.7547e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 7.0560e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 0.9999\n",
      "Epoch 18/100\n",
      "156/156 [==============================] - 3s 19ms/step - loss: 6.2147e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0259 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 5.1471e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0260 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 4.4673e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 3.8446e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 3.5224e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 3.0307e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "156/156 [==============================] - 4s 22ms/step - loss: 2.7787e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 2.3853e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0250 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 2.3587e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 2.0307e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9998\n",
      "Epoch 28/100\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 1.7738e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0252 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 1.7164e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 1.6324e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9585 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9871\n",
      "Epoch 32/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0317 - val_sparse_categorical_accuracy: 0.9997\n",
      "Epoch 33/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0307 - val_sparse_categorical_accuracy: 0.9996\n",
      "Epoch 34/100\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0286 - val_sparse_categorical_accuracy: 0.9998\n",
      "Epoch 35/100\n",
      "156/156 [==============================] - 3s 20ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0286 - val_sparse_categorical_accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "model = build_model(source_vocab_size, target_vocab_size, target_vocab_start, target_vocab_end, max_target_length, n_neurons=64, learning_rate=1e-2)\n",
    "train_model(preprocessed_train_set, preprocessed_val_set, model, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d577e4d-3564-4da4-884a-163f0c65c3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:13:24.908209Z",
     "iopub.status.busy": "2022-08-10T02:13:24.907680Z",
     "iopub.status.idle": "2022-08-10T02:13:25.274369Z",
     "shell.execute_reply": "2022-08-10T02:13:25.273600Z",
     "shell.execute_reply.started": "2022-08-10T02:13:24.908161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 6130-10-03$ pred 6130-10-03$\n",
      "target 5796-01-07$ pred 5796-01-07$\n",
      "target 7162-04-03$ pred 7162-04-03$\n",
      "target 818-10-25$ pred 818-10-25$\n",
      "target 220-08-15$ pred 220-08-15$\n",
      "target 4633-05-25$ pred 4633-05-25$\n",
      "target 5331-11-28$ pred 5331-11-28$\n",
      "target 7239-04-03$ pred 7239-04-03$\n",
      "target 6618-10-07$ pred 6618-10-07$\n",
      "target 7772-07-07$ pred 7772-07-07$\n",
      "target 1871-10-08$ pred 1871-10-08$\n",
      "target 4703-08-17$ pred 4703-08-17$\n",
      "target 4700-01-01$ pred 4700-01-01$\n",
      "target 2903-05-09$ pred 2903-05-09$\n",
      "target 8328-10-07$ pred 8328-10-07$\n",
      "target 2553-04-10$ pred 2553-04-10$\n",
      "target 1928-12-15$ pred 1928-12-15$\n",
      "target 4349-12-28$ pred 4349-12-28$\n",
      "target 3550-01-18$ pred 3550-01-18$\n",
      "target 4755-06-10$ pred 4755-06-10$\n",
      "target 6141-09-03$ pred 6141-09-03$\n",
      "target 9186-09-25$ pred 9186-09-25$\n",
      "target 3527-06-14$ pred 3527-06-14$\n",
      "target 8946-01-23$ pred 8946-01-23$\n",
      "target 8310-04-10$ pred 8310-04-10$\n",
      "target 6563-09-20$ pred 6563-09-20$\n",
      "target 5875-11-05$ pred 5875-11-05$\n",
      "target 1214-01-26$ pred 1214-01-26$\n",
      "target 7767-04-27$ pred 7767-04-27$\n",
      "target 2360-10-29$ pred 2360-10-29$\n",
      "target 7875-10-11$ pred 7875-10-11$\n",
      "target 526-01-05$ pred 526-01-05$\n"
     ]
    }
   ],
   "source": [
    "def categorical_to_target_string(seq):\n",
    "    vocab = target_preprocessor.get_vocabulary()\n",
    "    return \"\".join([vocab[i] for i in seq])\n",
    "\n",
    "for X, Y in preprocessed_val_set.take(1):\n",
    "    Y_pred = model(X)\n",
    "    for b in range(Y_pred.shape[0]):\n",
    "        seq = tf.math.argmax(Y_pred[b], axis=1)\n",
    "        s_target = categorical_to_target_string(Y[b])\n",
    "        s_pred = categorical_to_target_string(seq)\n",
    "        print(\"target\", s_target, \"pred\", s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85466553-4be2-4e86-80bd-85d39f0de0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T02:13:25.275990Z",
     "iopub.status.busy": "2022-08-10T02:13:25.275683Z",
     "iopub.status.idle": "2022-08-10T02:13:25.969618Z",
     "shell.execute_reply": "2022-08-10T02:13:25.968359Z",
     "shell.execute_reply.started": "2022-08-10T02:13:25.275973Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0260 - sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025971319526433945, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(preprocessed_test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
