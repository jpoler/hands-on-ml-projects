{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2425b52-89dc-4a34-a8ba-98b52ed5621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:14.951218Z",
     "iopub.status.busy": "2022-08-18T02:46:14.950600Z",
     "iopub.status.idle": "2022-08-18T02:46:16.984631Z",
     "shell.execute_reply": "2022-08-18T02:46:16.983480Z",
     "shell.execute_reply.started": "2022-08-18T02:46:14.951105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from transformers import pipeline, TFAutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling, create_optimizer, AdamWeightDecay\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85f9d45-edd8-4037-a99c-14e6015b625c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:16.986142Z",
     "iopub.status.busy": "2022-08-18T02:46:16.985703Z",
     "iopub.status.idle": "2022-08-18T02:46:17.233232Z",
     "shell.execute_reply": "2022-08-18T02:46:17.232114Z",
     "shell.execute_reply.started": "2022-08-18T02:46:16.986124Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tiny_shakespeare (/home/jon/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e)\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_dataset(\"tiny_shakespeare\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c759d2c1-747f-4975-b8c5-0c9699a37939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:17.235432Z",
     "iopub.status.busy": "2022-08-18T02:46:17.234794Z",
     "iopub.status.idle": "2022-08-18T02:46:20.005316Z",
     "shell.execute_reply": "2022-08-18T02:46:20.004455Z",
     "shell.execute_reply.started": "2022-08-18T02:46:17.235374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 22:46:18.371948: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-17 22:46:18.776742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22309 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2022-08-17 22:46:19.037246: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-08-17 22:46:19.597857: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc643543-c44b-46f8-8642-0dc6fb83c165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:20.007547Z",
     "iopub.status.busy": "2022-08-18T02:46:20.006754Z",
     "iopub.status.idle": "2022-08-18T02:46:20.024506Z",
     "shell.execute_reply": "2022-08-18T02:46:20.023672Z",
     "shell.execute_reply.started": "2022-08-18T02:46:20.007490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a655d549-fd3b-48ec-89bf-974f7ceb9bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:20.027282Z",
     "iopub.status.busy": "2022-08-18T02:46:20.026929Z",
     "iopub.status.idle": "2022-08-18T02:46:20.097747Z",
     "shell.execute_reply": "2022-08-18T02:46:20.097062Z",
     "shell.execute_reply.started": "2022-08-18T02:46:20.027251Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token_id = tokenizer.get_added_vocab()[\"[PAD]\"]\n",
    "pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3494a17-22e4-47f5-91f8-08cf165c80e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:20.098736Z",
     "iopub.status.busy": "2022-08-18T02:46:20.098455Z",
     "iopub.status.idle": "2022-08-18T02:46:20.106216Z",
     "shell.execute_reply": "2022-08-18T02:46:20.105495Z",
     "shell.execute_reply.started": "2022-08-18T02:46:20.098722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7640cbb9-92a1-40ae-967e-6a1a59920e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:20.107207Z",
     "iopub.status.busy": "2022-08-18T02:46:20.106960Z",
     "iopub.status.idle": "2022-08-18T02:46:20.159818Z",
     "shell.execute_reply": "2022-08-18T02:46:20.158989Z",
     "shell.execute_reply.started": "2022-08-18T02:46:20.107191Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jon/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e/cache-1bbf61aa6afd4bba.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = d.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddedfe27-3da4-4e91-a22d-7c3d7281395b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:20.161781Z",
     "iopub.status.busy": "2022-08-18T02:46:20.161185Z",
     "iopub.status.idle": "2022-08-18T02:46:20.592762Z",
     "shell.execute_reply": "2022-08-18T02:46:20.591653Z",
     "shell.execute_reply.started": "2022-08-18T02:46:20.161742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_from_input_ids(input_ids, window_size=100, batch_size=32, shuffle_buffer_size=10000):\n",
    "    return tf.data.Dataset.from_tensor_slices(input_ids) \\\n",
    "        .window(window_size+1, stride=1, drop_remainder=True) \\\n",
    "        .flat_map(lambda w: w.batch(window_size+1)) \\\n",
    "        .map(lambda w: {\"input_ids\": w[:-1], \"attention_mask\": tf.fill([window_size], 1), \"labels\": w[1:]}) \\\n",
    "        .shuffle(shuffle_buffer_size) \\\n",
    "        .batch(batch_size) \\\n",
    "        .prefetch(1)\n",
    "    \n",
    "    \n",
    "input_ids = lm_dataset[\"input_ids\"][0]\n",
    "split_idx = (len(input_ids) * 90) // 100\n",
    "\n",
    "train_ds = dataset_from_input_ids(input_ids[:split_idx])\n",
    "val_ds = dataset_from_input_ids(input_ids[split_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f257ad1d-ff10-41a8-8e22-039ac08ec133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:20.594798Z",
     "iopub.status.busy": "2022-08-18T02:46:20.594218Z",
     "iopub.status.idle": "2022-08-18T02:46:21.288117Z",
     "shell.execute_reply": "2022-08-18T02:46:21.287071Z",
     "shell.execute_reply.started": "2022-08-18T02:46:20.594755Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2744  1669    72 ...  1494  1549   198]\n",
      " [  326   561  6546 ...   561  5380   514]\n",
      " [17862    13   198 ...   198  2514  4467]\n",
      " ...\n",
      " [  514   284  6731 ... 13889    25   198]\n",
      " [  318  3750    11 ...    25   198    46]\n",
      " [   30   198  2348 ...    11 12891    11]], shape=(32, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]], shape=(32, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1669    72    25 ...  1549   198  1820]\n",
      " [  561  6546   616 ...  5380   514    11]\n",
      " [   13   198 12322 ...  2514  4467   345]\n",
      " ...\n",
      " [  284  6731    25 ...    25   198   464]\n",
      " [ 3750    11   290 ...   198    46    11]\n",
      " [  198  2348   292 ... 12891    11   290]], shape=(32, 100), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x in train_ds.take(1):\n",
    "    print(x[\"input_ids\"])\n",
    "    print(x[\"attention_mask\"])\n",
    "    print(x[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df388c0a-e9dd-4c29-8538-61d84c41b94f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:21.289743Z",
     "iopub.status.busy": "2022-08-18T02:46:21.289397Z",
     "iopub.status.idle": "2022-08-18T02:46:23.265848Z",
     "shell.execute_reply": "2022-08-18T02:46:23.264475Z",
     "shell.execute_reply.started": "2022-08-18T02:46:21.289712Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "We can only hope that when the wishes of the newspaper, first and foremost, we will not hesitate to return to it.\n",
      "DANIEL BIONCERT:\n",
      "Within a year, Mr\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "Our scenario involves free-falling and a new set of mission challenges based on the discovery of the fundamental origins of Mercury. The first five missions are planned and set up by post-flight operations and\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "Lima said in the immigration issue, her client was worried about not being heard, but that it was safe to say it was not an opportunity for anyone to get in contact with her.\n",
      "AB\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "The Treaty of Lincoln reached an agreement with Britain on October 9, 1825, following a six-day open debate about a clause of human rights prohibiting the invading force of the British.\n",
      "In subsequent\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "How will you explain this being a product of the NHS?\n",
      "CHARLOTT:\n",
      "Within a few weeks, not so long ago, most of us paid a service bill to people that it\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even though, as anything that moves as far as you want to go, the crowd of looking into a boat with an open trunk at the bottom is that the boats have suddenly lost the voice of an old\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even, it‼ber I‼ber it‼ber my political beliefs, those values and interests.\n",
      "\n",
      "\n",
      "But it‼ber in a campaign still seems to survive. \n",
      "\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even though your loyalty really lies in the dogged pursuit of individualism: People treat you like a little girl. Do you respect yourself? Do you get the idea you're an ex-boyfriend? I\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even with Texas' President-elect Donald Trump, we know a lot more about Breitbart's stories than many people could ever know about. But if we can get all that out of the way, we will\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find'spark a true light' (follows mine).\n",
      "3....seeing my God. /\n",
      "THE BEING (MEETHING)\n",
      "As I begin that trip, my dear the\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find is the word which I give it, which is the verb which I make clear unto you, which I make clear unto you, which I make clear unto you.\n",
      "Gryphorosos (\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find.\n",
      "Mark what I do, which you shall find.\n",
      "Mark what I do, which you shall find.\n",
      "Mark what I do, which you shall find.\n",
      "Mark what I do,\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find in my theocratic politics of the world (although the further that you follow these rules, then the more you are struck with the general public).\n",
      "\n",
      "Feminism is no exception to the various\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find in No. 11 on this page, may be by birth a shorter life, so that you may die a more definite. Do not die in that age; if you die, you might not die\n"
     ]
    }
   ],
   "source": [
    "input_length = 10\n",
    "generate_length = 40\n",
    "num_sequences = 5\n",
    "\n",
    "for item in val_ds.take(1):\n",
    "    example_input_ids = item[\"input_ids\"]\n",
    "\n",
    "def generate_text(model, input_ids):\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        do_sample=True,\n",
    "        max_length=generate_length + input_length,\n",
    "        temperature=1.0,\n",
    "        top_k=0,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0,\n",
    "        num_return_sequences=num_sequences,\n",
    "        pad_token_id=pad_token_id,\n",
    "    )\n",
    "    \n",
    "    return tokenizer.batch_decode(output_ids)\n",
    "\n",
    "\n",
    "outputs = generate_text(model, example_input_ids[:3, :input_length])\n",
    "for output in outputs:\n",
    "    print(\"===================\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa59e78-f623-4da2-b5c2-cf25fd3dda0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:23.268022Z",
     "iopub.status.busy": "2022-08-18T02:46:23.267448Z",
     "iopub.status.idle": "2022-08-18T02:46:23.273820Z",
     "shell.execute_reply": "2022-08-18T02:46:23.272756Z",
     "shell.execute_reply.started": "2022-08-18T02:46:23.267981Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e941a88-2705-4e11-91f7-2e89c3aecf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:23.275697Z",
     "iopub.status.busy": "2022-08-18T02:46:23.275251Z",
     "iopub.status.idle": "2022-08-18T02:46:23.310399Z",
     "shell.execute_reply": "2022-08-18T02:46:23.309220Z",
     "shell.execute_reply.started": "2022-08-18T02:46:23.275658Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4400ace7-7067-432b-9d1b-7c72e5594386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:46:23.311924Z",
     "iopub.status.busy": "2022-08-18T02:46:23.311510Z",
     "iopub.status.idle": "2022-08-18T02:47:22.063066Z",
     "shell.execute_reply": "2022-08-18T02:47:22.062346Z",
     "shell.execute_reply.started": "2022-08-18T02:46:23.311896Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "85/85 [==============================] - 20s 223ms/step - loss: 6.3883 - val_loss: 5.8824\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 5.6963 - val_loss: 5.6697\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 20s 223ms/step - loss: 5.4671 - val_loss: 5.5388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bf83d8dc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_ds, validation_data=val_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd8c89d-ce3c-4ca4-965f-9f50f2ea5a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-18T02:47:22.065330Z",
     "iopub.status.busy": "2022-08-18T02:47:22.064994Z",
     "iopub.status.idle": "2022-08-18T02:47:23.878232Z",
     "shell.execute_reply": "2022-08-18T02:47:23.877476Z",
     "shell.execute_reply.started": "2022-08-18T02:47:22.065310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      " that grace mind the and.\n",
      "AD ED IV\n",
      "BING:Good think I even prison would\n",
      " I that prison I live my; but hope\n",
      "is not my land;What can'd do\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      ", again, no no\n",
      " I am in one\n",
      " senate to senate thou ty.\n",
      "ISELL:O, shame my, that I\n",
      " notford's nor men away many\n",
      "ish look'd\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      ", I go to Ert andTh;I the more\n",
      " live all inul asement\n",
      " lie!- living drops eyes\n",
      "'t my\n",
      " amby great have sport them butI their\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "'ll me? sir sir,Will a good husband a to himself\n",
      "ty's and more?\n",
      "BRUS:No\n",
      " I a look in, meet like chamber\n",
      " some shade that vite silence\n",
      "===================\n",
      " afterwards.\n",
      "\n",
      "ABHORSON:\n",
      "at that you promised you\n",
      " might keep sir gain and shall make\n",
      " course to return pursuit thy, within.Beours to know,To bears me up town\n",
      " soon will make againAnd again\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even's thosecius\n",
      "an thatest of when were;\n",
      "cius that was teach best noble\n",
      " I.\n",
      "UT:Th twice andHe in with: I have\n",
      " drunk but thecius of pride\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even may good those; will\n",
      " you be well Well\n",
      " Raph, then four, your, goodly; would think he your?\n",
      "A:I no\n",
      " lack opinion theHe of them was\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even, indeed speakin live\n",
      " me me' you but byI out'd, to holy! andjoin followers and kins\n",
      " welcome foes can hell here into,And th thisSo spite world himProv\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even,.\n",
      "U ED:This must heaven\n",
      " needs too to prayer\n",
      " my-, I am sweet.,\n",
      "OLIO\n",
      "W:Good; well well do that too let,Why not\n",
      "===================\n",
      "?\n",
      "\n",
      "LUCIO:\n",
      "Good even friends well I have rather than young itIt hence far be to know\n",
      " and glad I. rest,.\n",
      "ELL:I, it tly doing wellYour cheeksay gone and of blood.\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find\n",
      "ate: cast thou. to death commorrow outOf art\n",
      " make all, I in for, about\n",
      " done sake.\n",
      "r:I then to queen lie in of; rest say mine\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find well\n",
      " face bloody: nor dead you\n",
      " thou art thou thy, me inself\n",
      " giving for thy soarer degree men\n",
      " I very request mya Godst and whatent, will\n",
      " they\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find\n",
      " deserve to may be death\n",
      " death it power the king cannot; must it those yourselves\n",
      " pay themselves an the;By with them the sign words\n",
      " Ty own the in with to five foring\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find in.\n",
      "First, Mark this noney,, should him?\n",
      "OLAR:But more, did you for that lord\n",
      " shall. for my, go and\n",
      " you upon both?Third\n",
      "===================\n",
      "\n",
      "Mark what I say, which you shall find\n",
      " me\n",
      " remedy what direction nature changed\n",
      " IT thou weary, now pains:I consider:With by time itOut in aliveAnd cradleTo full upI up ofWhich hast houseOf torture\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_text(model, example_input_ids[:3, :input_length])\n",
    "for output in outputs:\n",
    "    print(\"===================\")\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
