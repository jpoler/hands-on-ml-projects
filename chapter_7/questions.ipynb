{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9953727d",
   "metadata": {},
   "source": [
    "1. If you have trained five different models on the exact same training data, and they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?\n",
    "\n",
    "A more precise model can be achieved assuming that the models all make different kinds of mistakes. By allowing models to vote and choosing the mode, it is possible to achieve better precision due to most models being correct on any given instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5829c008",
   "metadata": {},
   "source": [
    "2. What is the difference between hard and soft voting classifiers?\n",
    "\n",
    "Hard voting classifiers choose the mode of votes. Soft voting classifiers average the probability of each class across all voting classifiers and then choose the maximum average probability. Soft classifiers can be more accurate because they put more weight on highly confident votes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e96847",
   "metadata": {},
   "source": [
    "3. Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers? What about pasting ensembles, boosting ensembles, Random Forests, or stacking ensembles?\n",
    "\n",
    "Bagging, pasting, and random forests can all be parallelized in a straightforward manner, because the samples can be generated and then partitioned across nodes.\n",
    "\n",
    "It would also be possible to parallelize parts of a stacking ensemble, namely the first layer. This can be done by sending separate models to different nodes, and training them on the entire training set. It is less straightforward to train the blender in a parallel fashion, but this might actually be possible if the training method is SGD, where the data is partitioned across nodes,  and lock step gradient updates from each participating node are broadcast to all other nodes and averaged. Another approach is for each node to compute some portion of the gradient, but this is more useful for models with a very large number of parameters, which is probably unnecessary for a blender. An alternative to broadcasting is to have a parameter server for the blender.\n",
    "\n",
    "Boosting (both adaptive boosting and gradient boosting) cannot be easily parallelized, because each classifier depends on the predictions of the previous classifier in the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cdcea",
   "metadata": {},
   "source": [
    "4. What is the benefit of out-of-bag evaluation?\n",
    "\n",
    "Out of bag evaluation allows model validation with a separate validation set or cross validation. This leaves more data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4389736",
   "metadata": {},
   "source": [
    "5. What makes Extra-Trees more random than regular Random Forests? How can this extra randomness help? Are Extra-Trees slower or faster than regular Random Forests?\n",
    "\n",
    "Random Forests already choose a random subset of features to consider for a split at each node. Extra Trees add to the randomization by also choosing random thresholds instead of the best possible threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5aa2a",
   "metadata": {},
   "source": [
    "6. If your AdaBoost ensemble underfits the training data, which hyperparameters should you tweak and how?\n",
    "\n",
    "Assuming that the base estimator is very low-capacity like decision stumps, one could consider using a higher capacity model, increasing n_estimators, or increasing learning_rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb480fc",
   "metadata": {},
   "source": [
    "7. If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?\n",
    "\n",
    "Decrease the learning rate, which shrinks the contribution from each tree. Alternatively early stopping can find the appropriate model complexity based on the validation curve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
